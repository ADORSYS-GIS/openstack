{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"OpenStack","text":""},{"location":"#project-structure","title":"Project structure","text":"<ul> <li><code>/docs</code> for documentation</li> <li><code>/assets</code> for assets</li> <li><code>/scripts</code> for scripts</li> </ul>"},{"location":"VLAN/","title":"Understanding VLANs and Their Operation","text":"<p>A VLAN (Virtual LAN) is an overlay layer 2 network that helps us organize devices into different groups connected to a virtual network on the physical network.</p> <p>VLANs help us partition a LAN into smaller virtual networks for security purposes. This allows us to have different logically distinct virtual networks rather than having many physical small LANs.</p> <p>Computers on the same network (LAN) communicate either through wireless access points (AP) or through ethernet cables. All computers on a LAN are connected to the same network switch.</p>"},{"location":"VLAN/#types-of-vlans","title":"Types of VLANs","text":"<p>There are two types of VLANs:</p> <ul> <li>Port-Based VLAN: A VLAN is assigned to a particular port, and any machine   connected to that port automatically joins that VLAN</li> <li>User-Based or Dynamic VLAN: VLANs are assigned based on user   authentication or other dynamic criteria</li> </ul>"},{"location":"VLAN/#network-architecture","title":"Network Architecture","text":"<pre><code>flowchart TD\n    subgraph \"Physical Network Infrastructure\"\n        SW[\"Switch\"]\n    end\n\n    subgraph \"VLAN 10 (Marketing)\"\n        PC1[\"Computer 1\\nIP: 192.168.10.2\\nVLAN 10\"]\n        PC2[\"Computer 2\\nIP: 192.168.10.3\\nVLAN 10\"]\n    end\n\n    subgraph \"VLAN 20 (Engineering)\"\n        PC3[\"Computer 3\\nIP: 192.168.20.2\\nVLAN 20\"]\n        PC4[\"Computer 4\\nIP: 192.168.20.3\\nVLAN 20\"]\n    end\n\n    subgraph \"VLAN 30 (Finance)\"\n        PC5[\"Computer 5\\nIP: 192.168.30.2\\nVLAN 30\"]\n        PC6[\"Computer 6\\nIP: 192.168.30.3\\nVLAN 30\"]\n    end\n\n    SW --- PC1\n    SW --- PC2\n    SW --- PC3\n    SW --- PC4\n    SW --- PC5\n    SW --- PC6\n\n    RT[\"Router\\n(Inter-VLAN Routing)\"]\n    SW --- RT\n\n    PC1 &lt;--&gt; PC2\n    PC3 &lt;--&gt; PC4\n    PC5 &lt;--&gt; PC6\n\n    PC1 &lt;-.-&gt; |\"Traffic Isolated\\nUnless Routed\"| PC3\n    PC3 &lt;-.-&gt; |\"Traffic Isolated\\nUnless Routed\"| PC5\n    PC5 &lt;-.-&gt; |\"Traffic Isolated\\nUnless Routed\"| PC1\n\n    classDef vlan10 fill:#ffcccc,stroke:#ff0000\n    classDef vlan20 fill:#ccffcc,stroke:#00ff00\n    classDef vlan30 fill:#ccccff,stroke:#0000ff\n    classDef network fill:#f9f9f9,stroke:#666666\n    classDef router fill:#ffffcc,stroke:#ffcc00\n\n    class PC1,PC2 vlan10\n    class PC3,PC4 vlan20\n    class PC5,PC6 vlan30\n    class SW network\n    class RT router</code></pre>"},{"location":"ansible_docs/","title":"Ansible","text":"<p>Ansible is an open-source automation tool used for automating applications, service orchestration, and server configuration management.</p>"},{"location":"ansible_docs/#prerequisites","title":"Prerequisites","text":"<p>Before diving into Ansible, installation is necessary. Follow the tutorial on how to install Ansible here:</p> <ul> <li>Ansible Installation</li> </ul>"},{"location":"ansible_docs/#features","title":"Features","text":"<p>Ansible provides several tools to facilitate server management:</p> <ul> <li>OpenSSH: Used for setting up SSH and generating keys for server   authentication</li> <li>Ad-hoc Commands: Used as alternatives to playbooks for quick and simple   tasks</li> <li>Playbooks: YAML files containing specific tasks to manage servers, used   for complex tasks</li> <li>Inventory File: Contains the list of servers grouped by categories for   organized management</li> </ul>"},{"location":"ansible_docs/#how-it-works","title":"How It Works","text":""},{"location":"ansible_docs/#ssh-configuration","title":"SSH Configuration","text":"<p>Ansible relies on SSH to authenticate and configure servers. While you can use a single SSH key for managing all servers, it is often recommended to use two separate keys:</p> <ul> <li>One for personal SSH logins</li> <li>Another specifically for automation with Ansible</li> </ul>"},{"location":"ansible_docs/#creation-of-ssh-keys","title":"Creation of SSH Keys","text":"<p>SSH is a key aspect that Ansible uses to connect remotely to servers, eliminating the need for credential passwords each time a user logs in.</p> <p>To create SSH keys for both personal use and automation, follow these steps:</p> <ul> <li>Personal Key (for interactive SSH/logins):</li> </ul> <pre><code>ssh-keygen -t ed25519 -f ~/.ssh/personal_key -C \"your_email@domain.com\"\n</code></pre> <ul> <li>Ansible Key (for automation tasks):</li> </ul> <pre><code>ssh-keygen -t ed25519 -f ~/.ssh/ansible_key -C \"ansible@$(hostname)\"\n</code></pre> <p>After creating the keys, copy them to the servers using:</p> <pre><code>ssh-copy-id -i ~/.ssh/ansible_key.pub user@server_ip\nssh-copy-id -i ~/.ssh/personal_key.pub user@server_ip\n</code></pre> <p>Replace <code>user@server_ip</code> with the appropriate username and IP address or hostname of your target server.</p> <p>For more details, see:</p> <ul> <li>SSH Configuration</li> </ul>"},{"location":"ansible_docs/#launching-a-playbook","title":"Launching a Playbook","text":"<p>Playbooks define the automation logic in a structured way. When you run a playbook, Ansible:</p> <ol> <li>Loads temporary modules to the remote server</li> <li>Executes the tasks (e.g., install packages, start services)</li> <li>Removes the modules after execution</li> </ol> <p>For more details on playbooks:</p> <ul> <li>Ansible Playbook Guide</li> </ul>"},{"location":"ansible_docs/#ad-hoc-commands","title":"Ad-hoc Commands","text":"<p>Ad-hoc commands are ideal for executing quick operations without creating a playbook. Examples include reboots, file transfers, and directory management.</p> <p>To learn more about ad-hoc commands, see:</p> <ul> <li>Ad-hoc Commands</li> <li>Ad-hoc (Ansible Docs)</li> </ul>"},{"location":"ansible_docs/#server-management","title":"Server Management","text":"<p>Ansible excels at server management by providing:</p> <ul> <li>Playbooks: Makes task handover between teams seamless, as all required   tasks are documented in playbooks</li> <li>Inventory Files: Organizes server IP addresses by groups, making it easy   to manage and assign tasks</li> <li>SSH Key: Automates authentication, making server access and management   more efficient</li> </ul>"},{"location":"ansible_docs/#what-if-ansible-becomes-outdated","title":"What If Ansible Becomes Outdated?","text":"<p>If Ansible becomes outdated or no longer maintained, other modern tools can be used for infrastructure automation and server management:</p> <ul> <li>Chef</li> <li>SaltStack</li> <li>Pulumi</li> <li>Puppet</li> </ul> <p>Each tool has its specific strengths:</p> Tools Language Best Used For Chef Ruby Complex enterprise environments SaltStack YAML Large-scale deployments Pulumi Various Cloud infrastructure and resource management Puppet Puppet DSL Large-scale environments"},{"location":"deploy-choice/","title":"OpenStack Deployment Technology Decision","text":""},{"location":"deploy-choice/#introduction-and-purpose","title":"Introduction and Purpose","text":"<p>This document provides the technical rationale for selecting OpenStack Ansible as our OpenStack deployment and lifecycle management solution. The evaluation compares three primary deployment approaches: Charmed OpenStack (MAAS + Juju), Kolla-Ansible, and OpenStack Ansible.</p>"},{"location":"deploy-choice/#scope","title":"Scope","text":"<p>This decision covers the deployment, configuration management, and operational lifecycle of OpenStack infrastructure services. The scope includes initial deployment, day-2 operations, upgrades, scaling, and troubleshooting workflows.</p> <p>Target Scale: This evaluation assumes a multi-node deployment with 3 controller nodes, 3-20 compute nodes, and 3 storage nodes, supporting 100-500 virtual machines in production.</p> <p>Deployment Mode: OpenStack Ansible supports flexible deployment modes configurable via inventory settings. Services can be deployed in LXC containers (default) or directly on metal using the <code>is_metal: true</code> property. This document assumes the default LXC container mode unless otherwise specified. See OpenStack Ansible Configuration Reference for deployment options.</p>"},{"location":"deploy-choice/#architecture-comparison-overview","title":"Architecture Comparison Overview","text":"<p>The following diagram illustrates the abstraction layers and deployment approaches for each technology:</p> <pre><code>graph TB\n    subgraph \"Charmed OpenStack\"\n        JC[Juju Controller]\n        MAAS[MAAS Server]\n        CH1[Charm: Nova]\n        CH2[Charm: Neutron]\n        CH3[Charm: Keystone]\n        JC --&gt; CH1\n        JC --&gt; CH2\n        JC --&gt; CH3\n        MAAS --&gt; JC\n    end\n\n    subgraph \"Kolla-Ansible\"\n        AP1[Ansible Playbooks]\n        DC1[Docker: Nova]\n        DC2[Docker: Neutron]\n        DC3[Docker: Keystone]\n        DR[Docker Runtime]\n        AP1 --&gt; DR\n        DR --&gt; DC1\n        DR --&gt; DC2\n        DR --&gt; DC3\n    end\n\n    subgraph \"OpenStack Ansible\"\n        AP2[Ansible Playbooks]\n        LXC1[LXC: Nova]\n        LXC2[LXC: Neutron]\n        LXC3[LXC: Keystone]\n        OS[Operating System]\n        AP2 --&gt; OS\n        OS --&gt; LXC1\n        OS --&gt; LXC2\n        OS --&gt; LXC3\n    end</code></pre>"},{"location":"deploy-choice/#deployment-architecture","title":"Deployment Architecture","text":""},{"location":"deploy-choice/#architecture-overview","title":"Architecture Overview","text":"<p>The deployment architecture implements a multi-tier OpenStack cloud with clear separation of control plane, data plane, and storage services across dedicated network planes. This design ensures optimal performance, security isolation, and operational maintainability.</p>"},{"location":"deploy-choice/#control-plane-components","title":"Control Plane Components","text":"<p>Controller Nodes (3x HA Cluster):</p> <ul> <li>Host all OpenStack API services (Nova, Neutron, Cinder, Glance,   Keystone, Horizon)</li> <li>Run clustered database services (MariaDB Galera cluster)</li> <li>Operate message queue services (RabbitMQ cluster)</li> <li>Provide load balancing and API endpoint management</li> <li>Handle authentication, authorization, and service orchestration</li> </ul> <p>Load Balancer:</p> <ul> <li>Distributes external API traffic across controller nodes</li> <li>Provides SSL termination and health checking</li> <li>Ensures high availability for all OpenStack APIs</li> <li>Routes dashboard (Horizon) traffic to active controllers</li> </ul>"},{"location":"deploy-choice/#data-plane-components","title":"Data Plane Components","text":"<p>Compute Nodes (3-20x):</p> <ul> <li>Run Nova compute service for VM lifecycle management</li> <li>Host Neutron L2/L3 agents for tenant networking</li> <li>Execute hypervisor operations (KVM/QEMU)</li> <li>Provide local storage for ephemeral disks</li> <li>Connect to all network planes for VM traffic isolation</li> </ul> <p>Network Nodes (Optional/Integrated):</p> <ul> <li>Handle Neutron L3 routing and NAT services</li> <li>Provide DHCP services for tenant networks</li> <li>Manage floating IP assignment and external connectivity</li> <li>Can be integrated into controller or compute nodes</li> </ul>"},{"location":"deploy-choice/#storage-plane-components","title":"Storage Plane Components","text":"<p>Storage Nodes (3x):</p> <ul> <li>Provide Cinder block storage services</li> <li>Host Swift object storage services</li> <li>Manage persistent volume attachments to VMs</li> <li>Implement storage replication and backup services</li> </ul>"},{"location":"deploy-choice/#network-plane-architecture","title":"Network Plane Architecture","text":"<p>Management Network:</p> <ul> <li>Carries OpenStack API traffic between services</li> <li>Handles Ansible deployment and configuration management</li> <li>Provides SSH access and monitoring traffic</li> <li>Isolated from tenant and external networks</li> </ul> <p>Tenant Network (Overlay):</p> <ul> <li>Carries east-west VM-to-VM traffic within projects</li> <li>Implements VXLAN/GRE tunneling for network isolation</li> <li>Provides L2/L3 services through Neutron agents</li> <li>Scales to support thousands of tenant networks</li> </ul> <p>Storage Network:</p> <ul> <li>Dedicated to Cinder and Swift storage traffic</li> <li>Carries iSCSI, NFS, or Ceph storage protocols</li> <li>Optimized for high throughput and low latency</li> <li>Isolated from other traffic types for performance</li> </ul> <p>External Network:</p> <ul> <li>Provides north-south connectivity to internet/WAN</li> <li>Handles floating IP traffic and external API access</li> <li>Routes traffic through provider networks</li> <li>Connects to organizational network infrastructure</li> </ul>"},{"location":"deploy-choice/#traffic-flow-patterns","title":"Traffic Flow Patterns","text":"<p>API Request Flow:</p> <ol> <li>External client \u2192 Load balancer \u2192 Controller node APIs</li> <li>API service \u2192 Database cluster (MariaDB Galera)</li> <li>API service \u2192 Message queue (RabbitMQ) \u2192 Target service</li> <li>Response flows back through same path with load balancer distribution</li> </ol> <p>VM East-West Traffic:</p> <ol> <li>VM \u2192 Compute node Neutron agent \u2192 Tenant network overlay</li> <li>VXLAN/GRE encapsulation across compute nodes</li> <li>Neutron L2/L3 agents handle routing and switching</li> <li>Traffic remains on tenant network plane throughout</li> </ol> <p>Storage I/O Flow:</p> <ol> <li>VM \u2192 Compute node \u2192 Storage network plane</li> <li>Cinder volume attachment via iSCSI/NFS protocols</li> <li>Storage nodes handle replication and backup</li> <li>Swift object access through dedicated storage APIs</li> </ol>"},{"location":"deploy-choice/#high-availability-and-redundancy","title":"High Availability and Redundancy","text":"<p>Controller HA:</p> <ul> <li>Active-active clustering for all API services</li> <li>MariaDB Galera 3-node cluster with automatic failover</li> <li>RabbitMQ cluster with message replication</li> <li>Load balancer health checks and automatic node removal</li> </ul> <p>Network Redundancy:</p> <ul> <li>Multiple network paths for each plane</li> <li>Neutron agent failover for L3 services</li> <li>VRRP for gateway redundancy</li> <li>Bond interfaces for physical network resilience</li> </ul> <p>Storage Resilience:</p> <ul> <li>Cinder volume replication across storage nodes</li> <li>Swift multi-replica object storage</li> <li>Backup and snapshot capabilities</li> <li>Cross-AZ storage distribution</li> </ul>"},{"location":"deploy-choice/#document-maintenance-note","title":"Document Maintenance Note","text":"<p>Architecture Updates: When the deployment architecture changes (new node types, additional network planes, scale modifications, or service relocations), update both this diagram and the corresponding explanation sections. Version the diagram files and reference the commit hash in deployment documentation.</p> <p>Deployment Mode Changes: If the deployment mode changes from the default LXC containers to bare-metal deployment (or vice versa), update both the diagram annotations and all explanatory text sections to reflect the new service deployment method. Update troubleshooting procedures and operational workflows accordingly.</p> <p>Review Schedule: Review architecture documentation quarterly and after major OpenStack releases to ensure accuracy and alignment with operational reality.</p>"},{"location":"deploy-choice/#candidate-technology-overviews","title":"Candidate Technology Overviews","text":""},{"location":"deploy-choice/#charmed-openstack-maas-juju","title":"Charmed OpenStack (MAAS + Juju)","text":"<p>Canonical's Charmed OpenStack combines Metal-as-a-Service (MAAS) for bare metal provisioning with Juju for application modeling and orchestration. This approach uses charms (application packages) to deploy and manage OpenStack services.</p> <p>Architecture: Model-driven deployment using Juju controllers, charms for service definitions, and MAAS for hardware lifecycle management. Services are deployed as applications with defined relationships and configurations.</p>"},{"location":"deploy-choice/#kolla-ansible","title":"Kolla-Ansible","text":"<p>Kolla-Ansible deploys OpenStack services using Docker containers orchestrated through Ansible playbooks. It provides containerized OpenStack services with standardized deployment patterns.</p> <p>Architecture: Container-based deployment where each OpenStack service runs in Docker containers. Ansible manages container orchestration, configuration, and lifecycle operations.</p>"},{"location":"deploy-choice/#openstack-ansible","title":"OpenStack Ansible","text":"<p>OpenStack Ansible deploys OpenStack services using Ansible playbooks and roles with configurable deployment modes. Services can be deployed in LXC containers (default) or directly on metal hosts using the <code>is_metal: true</code> inventory property.</p> <p>Architecture: Flexible deployment supporting both LXC containers and bare-metal installation. In container mode (default), services run within LXC containers managed by systemd. In metal mode (<code>is_metal: true</code>), services run directly on the host using systemd. Configuration is managed through comprehensive Ansible roles and inventory settings. See OpenStack Ansible Deployment Guide and Inventory Configuration Reference for deployment options.</p>"},{"location":"deploy-choice/#evaluation-criteria","title":"Evaluation Criteria","text":"<p>The following criteria guided our technology selection:</p> <ul> <li>Operational Transparency: Visibility into service configuration,   troubleshooting capabilities, and debugging workflows</li> <li>Customization Flexibility: Ability to modify configurations, integrate   custom components, and adapt to specific requirements</li> <li>Team Skill Alignment: Match with existing team expertise in   configuration management and infrastructure automation</li> <li>Upgrade Path Complexity: Simplicity and reliability of version upgrades   and maintenance operations</li> <li>Resource Overhead: System resource consumption and performance impact</li> <li>Community Support: Documentation quality, community activity, and   long-term viability</li> <li>Integration Capabilities: Compatibility with existing infrastructure   automation and monitoring systems</li> <li>Troubleshooting Complexity: Ease of diagnosing and resolving   operational issues</li> </ul>"},{"location":"deploy-choice/#technology-comparison-matrix","title":"Technology Comparison Matrix","text":"Criteria Charmed Kolla OpenStack Ansible Transparency Medium Low High Customization Low Medium High Team Skills Low Medium High Upgrades Medium High Medium Resources Medium High Low-Medium Community Medium Medium High Integration Low Medium High Troubleshooting High High Low <p>Table Legend:</p> <ul> <li>Charmed: Charmed OpenStack (MAAS + Juju)</li> <li>Kolla: Kolla-Ansible (Docker containers)</li> <li>Transparency: Operational visibility and debugging access</li> <li>Customization: Configuration flexibility and adaptation capability</li> <li>Team Skills: Alignment with existing team expertise</li> <li>Upgrades: Complexity of version upgrades and maintenance</li> <li>Resources: System resource consumption and overhead</li> <li>Community: Documentation quality and community support</li> <li>Integration: Compatibility with existing infrastructure</li> <li>Troubleshooting: Complexity rating (High = more complex)</li> </ul>"},{"location":"deploy-choice/#selected-approach-and-rationale","title":"Selected Approach and Rationale","text":"<p>OpenStack Ansible is selected as our deployment technology.</p>"},{"location":"deploy-choice/#primary-rationale","title":"Primary Rationale","text":"<p>Operational Transparency: OpenStack Ansible provides direct access to service configurations, logs, and system state through lightweight LXC containers. Services remain easily accessible via standard Linux tools (systemctl, journalctl, ps) while maintaining isolation. This transparency is critical for troubleshooting complex distributed systems and understanding service behavior during incidents.</p> <p>Team Skill Leverage: Our team has extensive Ansible expertise from existing infrastructure automation. OpenStack Ansible builds on this foundation rather than requiring new toolchain adoption (Juju/charms or Docker orchestration patterns).</p> <p>Customization Requirements: Our environment requires specific network configurations, security hardening, and integration with existing monitoring systems. OpenStack Ansible's role-based architecture allows granular customization without fighting framework constraints.</p> <p>Debugging Simplicity: When issues occur, OpenStack Ansible allows direct investigation of service configurations, LXC containers, and application logs without navigating complex container abstractions or Juju model complexities. Services can be accessed directly via <code>lxc-attach</code> or standard systemd commands.</p>"},{"location":"deploy-choice/#specific-advantages-over-alternatives","title":"Specific Advantages Over Alternatives","text":"<p>vs Charmed OpenStack:</p> <ul> <li>Eliminates Juju learning curve and operational complexity</li> <li>Removes dependency on MAAS for environments with existing provisioning</li> <li>Provides direct configuration control without charm limitations</li> <li>Simplifies troubleshooting by removing model abstraction layers</li> </ul> <p>vs Kolla-Ansible:</p> <ul> <li>Reduces resource overhead compared to Docker containers (LXC estimated   ~2-5% memory per service vs Docker's estimated ~15-20% per node, to be   validated in environment)</li> <li>Simplifies networking by avoiding Docker bridge networking complexity   (LXC uses host networking with namespace isolation)</li> <li>Enables direct service debugging through lightweight containers (access   via <code>lxc-attach</code> or host-level systemctl commands)</li> <li>Provides clearer upgrade paths without container image coordination (no   image registry dependencies or Docker version conflicts)</li> </ul>"},{"location":"deploy-choice/#risks-trade-offs-and-mitigations","title":"Risks, Trade-offs, and Mitigations","text":""},{"location":"deploy-choice/#identified-risks","title":"Identified Risks","text":"<p>Configuration Complexity: OpenStack Ansible requires more detailed configuration management compared to higher-level abstractions, with ~200+ configuration parameters across core services.</p> <ul> <li>Mitigation: Invest in comprehensive configuration templates, automated   validation (ansible-lint, yaml validation), and configuration drift   detection</li> </ul> <p>Service Dependency Management: Manual coordination of service dependencies during deployments and upgrades, requiring explicit ordering of 15+ interconnected services.</p> <ul> <li>Mitigation: Implement thorough testing procedures, staged deployment   processes with health checks, and automated rollback triggers</li> </ul> <p>Security Hardening Responsibility: Direct responsibility for service security configuration rather than framework defaults, including TLS certificates, firewall rules, and service authentication.</p> <ul> <li>Mitigation: Develop security baseline configurations, automated   compliance checking (OpenSCAP, custom Ansible security roles), and   regular security audits</li> </ul> <p>Operational Learning Curve: Team requires deep understanding of OpenStack service internals and interdependencies.</p> <ul> <li>Mitigation: Invest in comprehensive training, detailed runbook   development, and mentorship from OpenStack subject matter experts</li> </ul>"},{"location":"deploy-choice/#accepted-trade-offs","title":"Accepted Trade-offs","text":"<p>Higher Initial Configuration Effort: More upfront investment in playbook customization and testing compared to turnkey solutions.</p> <p>Manual Dependency Coordination: Requires explicit service dependency management rather than framework automation.</p> <p>Security Configuration Ownership: Full responsibility for security hardening rather than framework-provided defaults.</p>"},{"location":"deploy-choice/#operational-implications","title":"Operational Implications","text":""},{"location":"deploy-choice/#day-1-operations","title":"Day-1 Operations","text":"<ul> <li>Environment-specific configuration development using OpenStack Ansible's   provided playbooks, roles, and helper scripts (estimated 2-4 weeks for   customization)</li> <li>CI/CD pipeline integration leveraging OpenStack Ansible's   <code>bootstrap-ansible.sh</code> and <code>run-playbooks.sh</code> automation</li> <li>Custom variable files and inventory configuration for organizational   requirements</li> <li>Security baseline implementation and validation (CIS benchmarks,   organizational security policies)</li> <li>Network topology validation and service endpoint testing</li> <li>Performance baseline establishment and capacity planning</li> </ul>"},{"location":"deploy-choice/#day-2-operations","title":"Day-2 Operations","text":"<ul> <li>Direct service management: LXC container mode uses <code>lxc-attach</code> and   systemctl within containers; metal mode uses direct systemctl on host</li> <li>Log aggregation and monitoring integration with minimal container   complexity (direct syslog integration, native metric collection)</li> <li>Configuration drift detection and remediation through Ansible (scheduled   compliance runs, automated remediation)</li> <li>Capacity monitoring and scaling operations (horizontal compute scaling,   storage expansion)</li> <li>Backup and disaster recovery procedures (database backups, configuration   snapshots)</li> </ul>"},{"location":"deploy-choice/#upgrade-operations","title":"Upgrade Operations","text":"<ul> <li>Ansible playbook-driven upgrade processes with automated pre-flight checks</li> <li>Service-by-service upgrade coordination and validation (rolling upgrades   with health checks)</li> <li>Rollback procedures using configuration management state (automated   rollback triggers, configuration versioning)</li> <li>Database migration coordination and validation</li> <li>Post-upgrade testing and validation procedures</li> </ul>"},{"location":"deploy-choice/#troubleshooting-workflows","title":"Troubleshooting Workflows","text":"<ul> <li>Direct access to service logs and configurations: LXC mode via   <code>lxc-attach</code> and container logs; metal mode via direct host access</li> <li>Native debugging tools and processes (strace, tcpdump, service-specific   debugging)</li> <li>Clear service dependency and communication patterns (host networking with   namespace isolation in LXC mode)</li> <li>Performance profiling and bottleneck identification</li> <li>Root cause analysis procedures with direct system access</li> </ul>"},{"location":"deploy-choice/#validation-and-acceptance-criteria","title":"Validation and Acceptance Criteria","text":""},{"location":"deploy-choice/#technical-validation","title":"Technical Validation","text":"<ul> <li>[ ] Successful deployment of core OpenStack services across controller       nodes with all services reporting healthy status</li> <li>[ ] Controller HA cluster operational: MariaDB Galera 3-node cluster,       RabbitMQ cluster, load balancer health checks</li> <li>[ ] VM boot time &lt; 60 seconds for standard instances (target to be       validated in environment)</li> <li>[ ] API response times &lt; 2 seconds for standard operations through load       balancer (target to be validated)</li> <li>[ ] Network plane isolation verified: management, tenant, storage, and       external networks properly segregated</li> <li>[ ] East-west VM traffic flows correctly through tenant network overlay       (VXLAN/GRE) with &lt; 1ms latency (target)</li> <li>[ ] North-south traffic routing functional through external network and       floating IPs</li> <li>[ ] Storage I/O flows on dedicated storage network: Cinder IOPS &gt; 1000       (target), Swift throughput &gt; 100MB/s (target)</li> <li>[ ] Integration with existing monitoring and logging infrastructure       (Prometheus/Grafana, ELK stack)</li> <li>[ ] Security baseline implementation achieving 95% compliance with       organizational security policies</li> </ul>"},{"location":"deploy-choice/#operational-validation","title":"Operational Validation","text":"<ul> <li>[ ] Team proficiency demonstrated: 100% of team members can execute       standard deployment procedures independently</li> <li>[ ] Documented runbooks covering 15+ common operational scenarios       (service restart, node replacement, capacity expansion)</li> <li>[ ] Successful execution of upgrade procedures in test environment with       &lt; 5 minutes downtime per service</li> <li>[ ] Integration with existing change management: automated deployment       pipeline with approval gates</li> <li>[ ] Incident response time: P1 incidents acknowledged within 15 minutes,       initial response within 30 minutes</li> <li>[ ] Configuration drift detection: automated scanning every 4 hours,       remediation within 1 hour</li> </ul>"},{"location":"deploy-choice/#performance-validation","title":"Performance Validation","text":"<ul> <li>[ ] Controller node CPU utilization &lt; 70% during normal operations       (target baseline)</li> <li>[ ] Controller node memory utilization &lt; 80% during normal operations       (target baseline)</li> <li>[ ] Compute node overhead &lt; 10% of total resources including LXC       containers (target to be measured)</li> <li>[ ] Database response times &lt; 100ms for 95th percentile queries (target       to be validated)</li> <li>[ ] Message queue latency &lt; 50ms for 95th percentile operations (target       to be validated)</li> <li>[ ] Successful horizontal scaling: add compute node with &lt; 10 minutes       integration time (target)</li> <li>[ ] Network performance: tenant network throughput &gt; 80% of physical       network capacity (target)</li> </ul>"},{"location":"deploy-choice/#long-term-validation","title":"Long-term Validation","text":"<ul> <li>[ ] Successful completion of first major version upgrade (OpenStack       release) with &lt; 30 minutes total downtime</li> <li>[ ] Effective incident response: 90% of incidents resolved using       documented procedures and direct system access</li> <li>[ ] Team satisfaction survey: &gt; 80% satisfaction with operational       workflows and debugging capabilities</li> <li>[ ] Capacity planning accuracy: actual resource consumption within 15%       of projections</li> <li>[ ] Security compliance: pass quarterly security audits with zero       critical findings</li> </ul>"},{"location":"deploy-choice/#failure-mode-testing","title":"Failure Mode Testing","text":"<ul> <li>[ ] Controller node failure: automatic failover within 2 minutes, load       balancer removes failed node</li> <li>[ ] Database cluster failure: MariaDB Galera automatic failover within       60 seconds, zero data loss</li> <li>[ ] Message queue failure: RabbitMQ cluster maintains service continuity</li> <li>[ ] Compute node failure: VM evacuation and restart within 5 minutes</li> <li>[ ] Network plane failure: traffic isolation maintained, no cross-plane       contamination</li> <li>[ ] Storage node failure: Cinder/Swift replication maintains data       availability, performance degradation &lt; 20%</li> <li>[ ] Network partition: services continue operating in degraded mode,       automatic recovery upon reconnection</li> <li>[ ] Load balancer failure: API services remain accessible through backup       load balancer</li> </ul>"},{"location":"deploy-choice/#references-and-documentation","title":"References and Documentation","text":""},{"location":"deploy-choice/#openstack-ansible-documentation","title":"OpenStack Ansible Documentation","text":"<ul> <li>Official Documentation</li> <li>Deployment Guide</li> <li>Operations Guide</li> <li>Architecture Guide</li> </ul>"},{"location":"deploy-choice/#charmed-openstack","title":"Charmed OpenStack","text":"<ul> <li>Charmed OpenStack Documentation</li> <li>Juju Documentation</li> <li>MAAS Documentation</li> </ul>"},{"location":"deploy-choice/#kolla-ansible-documentation","title":"Kolla-Ansible Documentation","text":"<ul> <li>Kolla-Ansible Documentation</li> <li>Kolla Documentation</li> <li>Container Deployment Guide</li> </ul>"},{"location":"deploy-choice/#supporting-documentation","title":"Supporting Documentation","text":"<ul> <li>OpenStack Installation Guide</li> <li>Ansible Best Practices</li> <li>OpenStack Operations Guide</li> <li>OpenStack Security Guide</li> </ul>"},{"location":"netplan_doc/","title":"NETWORK CONFIGURATION USING NETPLAN WITH ANSIBLE","text":""},{"location":"netplan_doc/#what-is-netplan","title":"WHAT IS NETPLAN","text":"<p>Netplan is a modern network configuration tool, primarily used in Ubuntu-based Linux distributions. Its goal is to simplify the management of network interfaces through the use of YAML files. Before its introduction, network configuration in Linux was done through files like /etc/network/interfaces or other methods specific to the services used, like NetworkManager or systemd-networkd. With Netplan, these configurations are unified, providing a standard and accessible solution.</p> <p>This guide is designed to show you how to use Netplan with Ansible to efficiently configure your network interfaces, whether you need to manage Ethernet connections, Wi-Fi, or even advanced configurations like VLANs and static routes, alongside with Ansible to automate all these tedious processes.</p>"},{"location":"netplan_doc/#why-netplan","title":"WHY NETPLAN","text":"<p>Netplan was first introduced to the Ubuntu universe in version 17.10 (Artful Aardvark). Prior to this release, Linux server and system administrators often used traditional file and ifup/down/etc/network/interfaces tools to manage their network interfaces. These methods, while widely used, were becoming increasingly limited in modern, complex network environments.</p> <p>With the emergence of new needs, particularly around dynamic network management, the need for a tool that unifies the different network services has become apparent. Netplan is designed to fill this gap. It acts as an overlay simplifying the management of systemd-networkd (systemd is the network manager) and NetworkManager. This allows administrators to use a single, simplified syntax, regardless of the underlying service.</p> <p>Netplan is the choice for Ubuntu distributions that enabled a smoother transition to cloud infrastructures and virtualized environments, where tools like cloud-init benefit from automated and more flexible network configuration.</p>"},{"location":"netplan_doc/#network-managers","title":"Network Managers","text":"<p>As mentioned above, Netplan acts as a unified configuration interface for two main network managers: NetworkManager and systemd-networkd. Both services play a key role in managing network interfaces on Ubuntu distributions and their derivatives, but they are not used in the same contexts.</p>"},{"location":"netplan_doc/#network-manager","title":"Network Manager","text":"<p>NetworkManager is the network manager primarily used on desktop systems like Ubuntu Desktop or its graphical derivatives such as Kubuntu and Lubuntu. It is designed to simplify network connection management, especially in environments where interfaces change frequently, such as with Wi-Fi connections, VPNs, or mobile networks.</p> <p>On a system using NetworkManager, you often have access to a graphical interface, such as the one built into the GNOME desktop environment, to manage networks. This makes NetworkManager ideal for workstations where flexibility and user interaction are essential.</p>"},{"location":"netplan_doc/#systemd-networkd","title":"systemd-networkd","text":"<p>systemd-networkd, on the other hand, is more often used on server systems, such as Ubuntu Server, where network interface management is more static and does not require frequent user interaction. This service is minimalistic and seamlessly integrated into the systemd system, making it suitable for servers and headless environments.</p>"},{"location":"netplan_doc/#checking-your-network-manager","title":"Checking Your Network Manager","text":"<p>It is important to know which network manager is active, as it determines how Netplan will apply your network configuration.</p> <p>To check if NetworkManager is installed and active, you can run the following command:</p> <pre><code>sudo systemctl status NetworkManager\n</code></pre> <p>If the service is active, you will see a return indicating status as \"running\". Otherwise, the service will be inactive or uninstalled.</p> <p>To check if systemd-networkd is active, use the following command:</p> <pre><code>sudo systemctl status systemd-networkd\n</code></pre> <p>Similarly, if this service is active, it indicates that systemd-networkd is managing the network.</p>"},{"location":"netplan_doc/#netplan-file-structure-and-permissions","title":"Netplan File Structure and Permissions","text":"<p>The configuration files used by Netplan are in YAML format, a simple and readable format that makes it easy to configure network interfaces. These files are located in the directory /etc/netplan/ and it is from there that network configurations are applied.</p> <p>Each Netplan file follows a strict YAML syntax with well-defined indentations. Here is a simple example of a configuration where the Ethernet interface uses DHCP to obtain an IP address automatically:</p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n      dhcp4: true\n</code></pre> <p>Explanation:</p> <ul> <li>network: Main block that contains all network configurations.</li> <li>version: The version of the Netplan configuration file (version 2).</li> <li>renderer: Defines which service manages network configuration. Here, networkd   means that systemd-networkd is used. For a desktop environment, one can use   NetworkManager.</li> <li>ethernets: This block contains the Ethernet interfaces. In this example, eth0   is the interface being configured.</li> <li>dhcp4: Enables DHCP for IPv4, which assigns an IP address automatically.</li> </ul>"},{"location":"netplan_doc/#typical-configurations-with-netplan","title":"Typical Configurations with Netplan","text":"<p>Netplan is a flexible tool that allows you to configure different types of networks: IPv4 and IPv6 addresses, DHCP or static configurations, as well as more complex scenarios like network bridges, link aggregation (bonding), and Wi-Fi connections. Here is a set of typical configurations that cover these different cases.</p>"},{"location":"netplan_doc/#ipv4-configuration-with-dhcp","title":"IPv4 Configuration with DHCP","text":"<p>To configure a network interface with an IPv4 address obtained via DHCP, here is a simple configuration. This is commonly used for workstations or servers in environments where the IP address is automatically provided by a DHCP server:</p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n      dhcp4: true\n</code></pre> <p>In this example, the eth0 interface automatically obtains an IPv4 address via DHCP.</p>"},{"location":"netplan_doc/#configuring-a-fixed-ipv4-address","title":"Configuring a Fixed IPv4 Address","text":"<p>If you need a static IPv4 address for your interface, for example for a server, here's how to configure that:</p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n      addresses:\n        - 192.168.1.100/24\n      gateway4: 192.168.1.1\n      nameservers:\n        addresses:\n          - 8.8.8.8\n          - 8.8.4.4\n</code></pre> <ul> <li>addresses: Sets the static IP address with the subnet mask (/24).</li> <li>gateway4: Specifies the default gateway.</li> <li>nameservers: Defines the DNS servers (here, those of Google).</li> </ul>"},{"location":"netplan_doc/#ipv6-configuration-with-dhcp","title":"IPv6 Configuration with DHCP","text":"<p>To configure an interface to obtain an IPv6 address via DHCP, the syntax is similar to that for IPv4. Here's how to configure DHCP for IPv6 on Netplan:</p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n      dhcp6: true\n</code></pre> <p>This configuration allows the eth0 interface to obtain a dynamic IPv6 address via DHCPv6.</p>"},{"location":"netplan_doc/#configuring-a-static-ipv6-address","title":"Configuring a Static IPv6 Address","text":"<p>To set a static IPv6 address, here is an example configuration:</p> <pre><code>network:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n      addresses:\n        - 2001:0db8:85a3::8a2e:0370:7334/64\n      gateway6: 2001:0db8:85a3::1\n      nameservers:\n        addresses:\n          - 2001:4860:4860::8888\n          - 2001:4860:4860::8844\n</code></pre> <ul> <li>addresses: Specifies the static IPv6 address and its prefix (/64).</li> <li>gateway6: Sets the default gateway for IPv6.</li> <li>nameservers: Sets the DNS servers for IPv6.</li> </ul>"},{"location":"netplan_doc/#wi-fi-configuration","title":"Wi-Fi Configuration","text":"<p>Setting up a Wi-Fi network with Netplan requires specifying the SSID and security key. Here's an example of how to configure a Wi-Fi interface:</p> <pre><code>network:\n  version: 2\n  renderer: NetworkManager\n  wifis:\n    wlan0:\n      access-points:\n        \"MonSSID\":\n          password: \"motdepassewifi\"\n      dhcp4: true\n</code></pre> <p>In this example:</p> <ul> <li>wlan0 is the Wi-Fi interface.</li> <li>access-points specifies the Wi-Fi network name (MonSSID) and its password.</li> <li>dhcp4: true indicates that the Wi-Fi interface uses DHCP.</li> </ul>"},{"location":"netplan_doc/#checking-network-connectivity","title":"Checking Network Connectivity","text":"<p>If you have followed the Ubuntu server installation documentation, then there is no need to configure the network interface for Wi-Fi or ethernet manually, because it was surely configured during the installation of Ubuntu server. You may use the following command to ensure that network connection is well configured:</p> <pre><code>cat /etc/netplan/50-cloud-init.yaml\n</code></pre> <p>Also, you can use the following commands to check whether you are connected to the internet:</p> <pre><code>ping -c 5 8.8.8.8\n</code></pre> <p>OR</p> <pre><code>ping -c 5 google.com\n</code></pre> <p>If you see zero packet loss, all 5 packets were transmitted and 5 packets received, then it means that the DNS (Domain Name System) is able to resolve domain names to IP addresses and you are connected to the internet.</p>"},{"location":"netplan_doc/#configuring-network-interfaces-manually","title":"Configuring Network Interfaces Manually","text":"<p>If you want to configure Wi-Fi, static IPv4, static IPv6, IPv4 with DHCP, or IPv6 with DHCP manually, do the following:</p> <p>1- You need to:</p> <pre><code>sudo nano /etc/netplan/50-cloud-init.yaml\n</code></pre> <p>Then replace the configuration with any of the configurations above, depending on your choice.</p> <p>2- To apply the changes, run the following command:</p> <pre><code>netplan generate\nnetplan apply\n</code></pre>"},{"location":"netplan_doc/#configuring-network-interfaces-with-ansible","title":"Configuring Network Interfaces with Ansible","text":"<p>To configure any of these network interfaces manually using Ansible script, do the following:</p> <p>i. We need to install Ansible on our machine to be able to run Ansible scripts.    Run the following command to install Ansible:</p> <pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\nsudo apt install python3 \nsudo python3 venv my_venv | sudo source my_venv/bin/activate | cd my_venv\nsudo apt install -y build-essential libssl-dev libffi-dev python3-dev python3-pip\npython3 install ansible --user\n</code></pre> <p>ii. Create a playbook.yml file, copy and paste the following:</p> <pre><code>---\n- name: Configure Ethernet with static IP using Netplan\n  hosts: localhost\n  become: yes\n\n  vars:\n    interface_name: \"ens33\"\n    static_ip: \"10.42.0.10/24\"\n    gateway4: \"10.42.0.1\"\n    nameservers:   \n      - \"8.8.8.8\"\n      - \"8.8.4.4\"\n\n  tasks:\n    - name: Create Netplan configuration for Ethernet\n      copy:\n        dest: /etc/netplan/50-cloud-init.yaml\n        content: |\n          network:\n            version: 2\n            ethernets:\n              {{ interface_name }}:\n                dhcp4: no\n                addresses:\n                  - {{ static_ip }}\n                gateway4: {{ gateway4 }}\n                nameservers:\n                  addresses: {{ nameservers }}\n      notify: Apply Netplan\n\n  handlers:\n    - name: Apply Netplan\n      command: netplan apply\n\n    - name: Check interface IP using ip a\n      command: ip -4 addr show {{ interface_name }}\n      register: ip_result\n\n    - name: Display interface IP info\n      debug:\n        var: ip_result.stdout_lines\n</code></pre> <p>iii. To execute the Ansible code, run this command:</p> <pre><code>sudo ansible-playbook -i host playbook.yaml\n</code></pre> <p>If your output looks like this:</p> <pre><code>inet 192.168.1.100/24 brd 192.168.1.255 scope global ens33\n</code></pre> <p>Then this indicates that your network interface \"ens33\" has been configured.</p> <p>Alternatively, if you want to configure a wireless network interface with a static IP address (i.e., a network interface that uses Wi-Fi), replace the content in the /etc/netplan/50-cloud-init.yaml file with the following Ansible script:</p> <pre><code>---\n- name: Configure Wi-Fi with static IP using Netplan\n  hosts: localhost\n  become: yes\n\n  vars:\n    wifi_name: \"your_wifi_ssid\"\n    static_ip: \"192.168.1.100/24\"\n    interface_name: \"wlan0\"\n\n  tasks:\n    - name: Create Netplan configuration for Wi-Fi\n      copy:\n        dest: /etc/netplan/50-cloud-init.yaml\n        content: |\n          network:\n            version: 2\n            wifis:\n              {{ interface_name }}:\n                dhcp4: no\n                addresses:\n                  - {{ static_ip }}\n                gateway4: 192.168.1.1\n                nameservers:\n                  addresses:\n                    - 8.8.8.8\n                    - 8.8.4.4\n                access-points:\n                  \"{{ wifi_name }}\":\n                    password: \"your_wifi_password\"\n      notify: Apply Netplan\n\n    - name: Check interface IP using ip a\n      command: ip -4 addr show {{ interface_name }}\n      register: ip_result\n\n    - name: Display interface IP info\n      debug:\n        var: ip_result.stdout_lines\n\n  handlers:\n    - name: Apply Netplan\n      command: netplan apply\n</code></pre> <p>If your output looks like this:</p> <pre><code>inet 192.168.1.100/24 brd 192.168.1.255 scope global wlan0\n</code></pre> <p>Then this indicates that your network interface \"wlan0\" has been configured.</p>"},{"location":"ntp_docs/","title":"NTP","text":"<p>NTP (Network Time Protocol) is a protocol used to synchronize system time across multiple servers over a network. Accurate time synchronization is essential for coordination, security, and consistency in distributed systems and cloud infrastructures.</p>"},{"location":"ntp_docs/#time-server","title":"Time Server","text":"<p>A time server is a system that responds to time synchronization requests from other devices over a network. When it uses the Network Time Protocol (NTP) to provide accurate time, it is called an NTP server.</p>"},{"location":"ntp_docs/#why-ntp-server","title":"Why NTP Server?","text":"<p>Time synchronization plays a critical role in distributed systems, especially in large cloud infrastructures such as OpenStack. Below are key reasons why NTP servers are essential:</p> <ul> <li>Token-based authentication:</li> </ul> <p>In large cloud infrastructures like OpenStack, time synchronization is   critical because authentication tokens are time-sensitive. If a server's   system clock is not synchronized, it may reject valid tokens with errors such   as \"not yet valid\" or \"expired.\" NTP ensures consistent and accurate time   across all nodes in the infrastructure, helping to prevent such   authentication failures.</p> <ul> <li>Logs consistency issues:</li> </ul> <p>In large cloud infrastructures, services often run across multiple servers.   Without proper time synchronization, each server may record log entries using   slightly different timestamps. This makes it difficult to trace errors across   multiple systems. By using NTP, all servers maintain a consistent system   time, ensuring logs are aligned and easier to interpret during debugging or   audits.</p> <ul> <li>Scheduled jobs:</li> </ul> <p>Certain tasks or jobs may need to run simultaneously across multiple servers.   If server clocks are not synchronized, these actions may execute at   inconsistent times, leading to failures, data corruption, or unexpected   behavior. NTP ensures that all servers maintain a consistent system time,   enabling coordinated and predictable task execution.</p> <p>An NTP server is a fundamental component in any cloud or distributed infrastructure. It ensures reliable communication, secure authentication, synchronized logging, and proper task execution by keeping all systems aligned in time.</p>"},{"location":"netbird/netbird_access_review/","title":"NetBird Access Review Process","text":"<p>This document defines the periodic review process for NetBird group memberships, ACLs, and network routes.</p>"},{"location":"netbird/netbird_access_review/#review-schedule","title":"Review Schedule","text":"Review Type Frequency Scope Group Membership Review Monthly User group assignments ACL Review Quarterly Access control policies Network Routes Review Quarterly Route configurations Comprehensive Review Annually All components"},{"location":"netbird/netbird_access_review/#review-process","title":"Review Process","text":""},{"location":"netbird/netbird_access_review/#management-interface","title":"Management Interface","text":"<p>NetBird administrative functions are managed through: - NetBird Management Dashboard: https://app.netbird.io (or self-hosted instance) - NetBird Management API: For programmatic access</p> <p>Note: User management, groups, ACLs, and routes are not managed via the NetBird client CLI.</p> <p>Self-Hosted Dashboard Port Conflicts</p> <p>If deploying a self-hosted NetBird dashboard, ensure no conflicts with existing web servers. The dashboard typically uses ports 80 (HTTP) and 443 (HTTPS). Before deployment:</p> <p>Option 1: Stop conflicting services (Apache2/Nginx): <pre><code>sudo systemctl stop apache2  # or nginx\nsudo systemctl disable apache2  # or nginx\n</code></pre></p> <p>Option 2: Configure the dashboard to use alternative ports (e.g., 8080/8443) and access via <code>http://your-server:8080</code>.</p>"},{"location":"netbird/netbird_access_review/#review-categories","title":"Review Categories","text":""},{"location":"netbird/netbird_access_review/#1-group-membership-review","title":"1. Group Membership Review","text":"<p>Checklist: - [ ] Verify user role assignments - [ ] Check for inactive accounts - [ ] Validate group membership changes - [ ] Document access modifications</p> <p>Management: Use NetBird Management Dashboard to review and modify group memberships.</p>"},{"location":"netbird/netbird_access_review/#2-access-control-lists-acls-review","title":"2. Access Control Lists (ACLs) Review","text":"<p>Checklist: - [ ] Review ACL rule configurations - [ ] Validate network access permissions - [ ] Check for overly permissive rules - [ ] Verify security boundary enforcement</p> <p>Management: Access ACL policies through NetBird Management Dashboard or API.</p>"},{"location":"netbird/netbird_access_review/#3-network-routes-review","title":"3. Network Routes Review","text":"<p>Checklist: - [ ] Verify route configurations - [ ] Check network segmentation - [ ] Validate route priorities - [ ] Review unused routes</p> <p>Commands: <pre><code># List available network routes\nnetbird networks list\n</code></pre></p>"},{"location":"netbird/netbird_access_review/#review-documentation","title":"Review Documentation","text":""},{"location":"netbird/netbird_access_review/#review-record-template","title":"Review Record Template","text":"Field Details Review Date YYYY-MM-DD Reviewer Name and Title Review Type Monthly/Quarterly/Annual Changes Made Summary of modifications Next Review Date YYYY-MM-DD"},{"location":"netbird/netbird_access_review/#review-ownership-and-change-management","title":"Review Ownership and Change Management","text":""},{"location":"netbird/netbird_access_review/#review-ownership","title":"Review Ownership","text":"Review Type Primary Owner Secondary Owner Approver Group Membership IT Security Manager HR Representative Department Head ACL Policies Network Administrator Security Analyst CISO Network Routes Network Administrator Infrastructure Lead IT Director"},{"location":"netbird/netbird_access_review/#change-documentation-requirements","title":"Change Documentation Requirements","text":"<p>All access changes must include: - Business justification for the change - Risk assessment (Low/Medium/High) - Approval from designated authority - Implementation date and time - Rollback plan (if applicable)</p> <p>Change Documentation Template: <pre><code>Change ID: CHG-YYYYMMDD-XXX\nRequester: [Name and Department]\nBusiness Justification: [Reason for change]\nRisk Level: [Low/Medium/High]\nApproved By: [Approver Name and Date]\nImplemented By: [Implementer Name]\nImplementation Date: [YYYY-MM-DD HH:MM]\nRollback Plan: [Steps to reverse if needed]\nVerification: [How success was confirmed]\n</code></pre></p>"},{"location":"netbird/netbird_access_review/#exception-handling","title":"Exception Handling","text":"<p>Emergency Access Exceptions: - Must be approved by CISO or delegate - Limited to 24-hour duration maximum - Require immediate documentation - Subject to next-day review and formal approval</p> <p>Permanent Exceptions: - Require formal risk assessment - Must be approved by IT Director and CISO - Subject to quarterly review - Documented with compensating controls</p>"},{"location":"netbird/netbird_access_review/#review-execution","title":"Review Execution","text":""},{"location":"netbird/netbird_access_review/#pre-review-preparation","title":"Pre-Review Preparation","text":"<ol> <li>Access NetBird Management Dashboard</li> <li>Export current configurations</li> <li>Gather HR data for user status verification</li> <li>Prepare review templates and checklists</li> </ol>"},{"location":"netbird/netbird_access_review/#review-process_1","title":"Review Process","text":"<ol> <li>Conduct systematic review using provided checklists</li> <li>Document all findings in review templates</li> <li>Identify required changes and exceptions</li> <li>Obtain necessary approvals for modifications</li> <li>Implement approved changes through proper channels</li> <li>Verify changes were applied correctly</li> <li>Update documentation and schedule next review</li> </ol>"},{"location":"netbird/netbird_troubleshooting/","title":"NetBird Network Troubleshooting Guide","text":"<p>This guide provides comprehensive troubleshooting steps for NetBird network connectivity issues, focusing on outbound UDP traffic validation as specified in ticket #76.</p> <p>Purpose: Document troubleshooting steps including validation of outbound UDP traffic and provide systematic approach to resolve NetBird connectivity issues.</p>"},{"location":"netbird/netbird_troubleshooting/#troubleshooting-workflow","title":"Troubleshooting Workflow","text":"<pre><code>flowchart TD\n    A[Start Troubleshooting] --&gt; B[Check NetBird Service Status]\n    B --&gt; C{Service Running?}\n    C --&gt;|No| D[Start NetBird Service]\n    C --&gt;|Yes| E[Configuration Validation]\n    D --&gt; E\n\n    E --&gt; F[DNS Resolution Test]\n    F --&gt; G{DNS Success?}\n    G --&gt;|No| H[Check DNS Configuration]\n    G --&gt;|Yes| I[TCP Connectivity Test]\n    H --&gt; I\n\n    I --&gt; J{TCP Success?}\n    J --&gt;|No| K[Check Firewall/NAT Rules]\n    J --&gt;|Yes| L[Outbound UDP Probe]\n    K --&gt; L\n\n    L --&gt; M{UDP Success?}\n    M --&gt;|No| N[Test TCP/TLS Fallback]\n    M --&gt;|Yes| O[WireGuard Handshake Validation]\n    N --&gt; P[Generate Debug Bundle]\n    P --&gt; O\n\n    O --&gt; Q{Handshake Success?}\n    Q --&gt;|No| R[Check Logs and Debug Info]\n    Q --&gt;|Yes| S[Verify Internal Routing]\n    R --&gt; T[Escalate with Debug Data]\n    S --&gt; U[Network Connectivity Verified]\n    T --&gt; U</code></pre>"},{"location":"netbird/netbird_troubleshooting/#troubleshooting-steps","title":"Troubleshooting Steps","text":""},{"location":"netbird/netbird_troubleshooting/#1-check-netbird-service-status","title":"1. Check NetBird Service Status","text":"<pre><code># Check NetBird service status\nsudo systemctl status netbird\n\n# Check NetBird client status\nnetbird status\n\n# Check detailed peer status with connection information\nnetbird status --detail\n</code></pre>"},{"location":"netbird/netbird_troubleshooting/#2-configuration-validation","title":"2. Configuration Validation","text":"<p>Validate NetBird configuration before proceeding with connectivity tests:</p> <pre><code># Check NetBird version\nnetbird version\n\n# Check detailed status including management server connection\nnetbird status --detail\n\n# Look for configuration files in common locations\n# For standard installations:\nls -la /etc/netbird/\n# For Snap installations:\nls -la /var/snap/netbird/common/\n\n# Verify management server connectivity from status\nnetbird status --detail | grep -E \"(Management|Signal):\"\n</code></pre> <p>Configuration Checklist: - [ ] NetBird client version is current - [ ] Management server shows \"Connected\" in status - [ ] Signal server shows \"Connected\" in status - [ ] Configuration files exist in expected location - [ ] TLS certificates are valid (for self-hosted instances)</p> <p>Note: Configuration file paths vary by installation method: - Standard/self-hosted: <code>/etc/netbird/config.json</code> - Snap installations: <code>/var/snap/netbird/common/</code></p>"},{"location":"netbird/netbird_troubleshooting/#3-dns-resolution-test","title":"3. DNS Resolution Test","text":"<pre><code># Test DNS resolution for management server\ndig +short api.netbird.io\n\n# Test DNS resolution for signal server\ndig +short signal.netbird.io\n\n# Test STUN server resolution\ndig +short stun.l.google.com\n</code></pre>"},{"location":"netbird/netbird_troubleshooting/#4-tcp-connectivity-test","title":"4. TCP Connectivity Test","text":"<pre><code># Test HTTPS connectivity to management server\ncurl -I --connect-timeout 10 https://api.netbird.io:443\n\n# Test using netcat for basic connectivity\nnc -zv api.netbird.io 443\n</code></pre>"},{"location":"netbird/netbird_troubleshooting/#5-outbound-udp-traffic-validation","title":"5. Outbound UDP Traffic Validation","text":"<p>Required Ports and Endpoints (Reference: NetBird Docs \u2192 FAQ \u2192 What firewall ports should I open):</p> <p>NetBird Cloud Services: - Management Server: <code>api.netbird.io</code> - TCP/443 - Signal Server: <code>signal.netbird.io</code> - TCP/443 - STUN Server: <code>stun.netbird.io</code> - UDP/80,443,3478,5555 - TURN Server: <code>turn.netbird.io</code> - UDP/80,443 and TCP/443-65535 - Relay Service: <code>*.relay.netbird.io</code> - TCP/443</p> <p>Self-Hosted Requirements (Reference: NetBird Docs \u2192 Advanced Guide \u2192 Requirements): - Management: TCP/33073 (gRPC), TCP/33080 (HTTP API) - Signal: TCP/10000 (gRPC API) - Dashboard: TCP/80, TCP/443 (HTTP &amp; HTTPS) - Coturn (STUN/TURN): UDP/3478 (listening), UDP/49152-65535 (dynamic relay range)</p> <p>Port Conflict Warning</p> <p>Before starting the NetBird self-hosted dashboard, check if Apache2, Nginx, or any other HTTP/HTTPS service is running on the same server \u2014 they may already occupy ports 80 and 443. To avoid conflicts:</p> <p>Option 1: Stop/disable the conflicting service: <pre><code># For Apache2\nsudo systemctl stop apache2\nsudo systemctl disable apache2\n\n# For Nginx\nsudo systemctl stop nginx\nsudo systemctl disable nginx\n</code></pre></p> <p>Option 2: Change the NetBird dashboard listening ports (e.g., 8080 for HTTP, 8443 for HTTPS) in your NetBird configuration and access the dashboard via <code>http://your-server:8080</code> or <code>https://your-server:8443</code>.</p>"},{"location":"netbird/netbird_troubleshooting/#stun-server-connectivity","title":"STUN Server Connectivity","text":"<pre><code># Test NetBird STUN server connectivity (multiple ports)\nnc -u -v stun.netbird.io 3478 &lt; /dev/null\nnc -u -v stun.netbird.io 5555 &lt; /dev/null\n\n# Alternative using timeout\ntimeout 5 nc -u stun.netbird.io 3478 &lt; /dev/null\necho $?  # Should return 0 for success\n\n# Test fallback STUN servers\nnc -u -v stun.l.google.com 19302 &lt; /dev/null\n</code></pre>"},{"location":"netbird/netbird_troubleshooting/#tcptls-fallback-testing","title":"TCP/TLS Fallback Testing","text":"<p>If UDP is blocked, NetBird can fall back to TCP/TLS via TURN servers:</p> <pre><code># Test TURN server TCP connectivity\nnc -zv turn.netbird.io 443\n\n# Test TURN over TCP (if UDP fails)\ncurl -I --connect-timeout 10 https://turn.netbird.io:443\n</code></pre>"},{"location":"netbird/netbird_troubleshooting/#packet-capture-for-udp-analysis","title":"Packet Capture for UDP Analysis","text":"<pre><code># Capture UDP traffic on NetBird interface\nsudo tcpdump -i wt0 -n udp\n\n# Capture traffic to specific STUN server\nsudo tcpdump -i any -n \"host stun.l.google.com and udp port 3478\"\n\n# Monitor for TURN fallback traffic\nsudo tcpdump -i any -n \"host turn.netbird.io and tcp port 443\"\n</code></pre>"},{"location":"netbird/netbird_troubleshooting/#6-wireguard-status-check","title":"6. WireGuard Status Check","text":"<pre><code># Show WireGuard interface status\nsudo wg show\n\n# Check NetBird peer status with detailed information\nnetbird status --detail\n</code></pre> <p>Expected Output Example (Reference: NetBird Docs \u2192 Troubleshooting Client Issues \u2192 NetBird agent status):</p> <pre><code>Peers detail:\nserver-a.netbird.cloud:\n  NetBird IP: 100.75.232.118/32\n  Public key: kndklnsakldvnsld+XeRF4CLr/lcNF+DSdkd/t0nZHDqmE=\n  Status: Connected\n  -- detail --\n  Connection type: P2P\n  Direct: true\n  ICE candidate (Local/Remote): host/host\n  ICE candidate endpoints (Local/Remote): 10.128.0.35:51820/10.128.0.54:51820\n  Last connection update: 20 seconds ago\n  Last Wireguard handshake: 19 seconds ago\n  Transfer status (received/sent) 6.1 KiB/20.6 KiB\n  Quantum resistance: false\n  Routes: 10.0.0.0/24\n  Latency: 37.503682ms\n\nserver-b.netbird.cloud:\n  NetBird IP: 100.75.226.48/32\n  Status: Connected\n  -- detail --\n  Connection type: Relayed\n  Direct: false\n  ICE candidate (Local/Remote): relay/host\n  ICE candidate endpoints (Local/Remote): 108.54.10.33:60434/10.128.0.12:51820\n  Last Wireguard handshake: 18 seconds ago\n\nOS: darwin/amd64\nDaemon version: 0.27.4\nCLI version: 0.27.4\nManagement: Connected to https://api.netbird.io:443\nSignal: Connected to https://signal.netbird.io:443\nRelays: [stun:turn.netbird.io:5555] is Available\n        [turns:turn.netbird.io:443?transport=tcp] is Available\nNetBird IP: 100.75.143.239/16\nInterface type: Kernel\nPeers count: 2/2 Connected\n</code></pre> <p>Key Status Indicators: - Connection type: <code>P2P</code> (direct) vs <code>Relayed</code> (via TURN server) - Direct: <code>true</code> indicates direct peer connection, <code>false</code> uses relay - ICE candidates: <code>host/host</code> (direct), <code>relay/host</code> (one peer via relay) - Last Wireguard handshake: Should be &lt; 2 minutes for active connections - Management/Signal: Should show \\\"Connected to\\\" with HTTPS URLs</p>"},{"location":"netbird/netbird_troubleshooting/#7-firewall-and-nat-configuration","title":"7. Firewall and NAT Configuration","text":"<pre><code># Check iptables rules\nsudo iptables -L -n -v\n\n# Check UFW status (Ubuntu)\nsudo ufw status verbose\n</code></pre> <p>Required Firewall Rules (Reference: NetBird Docs \u2192 FAQ \u2192 Outgoing ports):</p> <p>For NetBird Cloud: - Allow outbound TCP/443 to <code>api.netbird.io</code>, <code>signal.netbird.io</code> - Allow outbound UDP/80,443,3478,5555 to <code>stun.netbird.io</code> - Allow outbound UDP/80,443 and TCP/443-65535 to <code>turn.netbird.io</code> - Allow outbound TCP/443 to <code>*.relay.netbird.io</code> - Allow traffic on NetBird interface (typically <code>wt0</code> or <code>nb-*</code>) - Allow established and related connections for return traffic</p> <p>For Self-Hosted NetBird: - Allow outbound TCP/33073, TCP/33080 (Management) - Allow outbound TCP/10000 (Signal) - Allow outbound UDP/3478 and UDP/49152-65535 (Coturn STUN/TURN)</p> <p>Interface Names: NetBird typically uses <code>wt0</code> (WireGuard) or <code>nb-*</code> interface names. Check with <code>ip link show</code> to verify actual interface names in your environment.</p> <p>Edge Cases and Advanced Troubleshooting:</p> <pre><code># Check for corporate firewall/proxy blocking\ncurl -v --proxy-header \"Host: api.netbird.io\" https://api.netbird.io\n\n# Test from different network locations to isolate ISP blocking\n# Check NAT traversal capabilities\nnetbird status --detail | grep -E \"(Connection type|ICE|Relay)\"\n\n# Verify TURN relay usage when direct connection fails\nnetbird status --detail | grep \"Relayed\"\n</code></pre> <p>NAT/Firewall Troubleshooting: - Corporate Firewalls: May block UDP entirely, requiring TURN over TCP - ISP Blocking: Some ISPs block UDP on non-standard ports - Symmetric NAT: May prevent direct P2P connections, forcing relay usage - Return Traffic: Ensure stateful firewall allows return packets</p>"},{"location":"netbird/netbird_troubleshooting/#common-issues","title":"Common Issues","text":""},{"location":"netbird/netbird_troubleshooting/#dns-resolution-failures","title":"DNS Resolution Failures","text":"<pre><code># Check DNS configuration\ncat /etc/resolv.conf\n\n# Test with different DNS servers\ndig @8.8.8.8 api.netbird.io\n</code></pre>"},{"location":"netbird/netbird_troubleshooting/#udp-traffic-blocked","title":"UDP Traffic Blocked","text":"<pre><code># Add firewall rules for UDP traffic\nsudo ufw allow out 3478/udp\nsudo ufw allow out 5349/udp\n</code></pre>"},{"location":"netbird/netbird_troubleshooting/#wireguard-interface-issues","title":"WireGuard Interface Issues","text":"<pre><code># Restart NetBird service\nsudo systemctl restart netbird\n\n# Check kernel module\nlsmod | grep wireguard\n</code></pre>"},{"location":"netbird/netbird_troubleshooting/#logging-and-debug-information","title":"Logging and Debug Information","text":""},{"location":"netbird/netbird_troubleshooting/#log-file-locations","title":"Log File Locations","text":"<pre><code># NetBird service logs\njournalctl -u netbird -f\n\n# NetBird client logs (if configured - path may vary by installation)\ntail -f /var/log/netbird/client.log\n\n# System logs for network issues\njournalctl -f | grep -E \"(netbird|wg|wireguard)\"\n</code></pre>"},{"location":"netbird/netbird_troubleshooting/#generate-debug-bundle","title":"Generate Debug Bundle","text":"<p>Reference: NetBird Docs \u2192 Troubleshooting Client Issues \u2192 Debug bundle</p> <pre><code># Create comprehensive debug bundle with system info\nnetbird debug bundle --anonymize --system-info\n\n# Generate debug info for specific duration (recommended for connection issues)\nnetbird debug for 5m --system-info\n\n# Upload debug bundle directly to NetBird support (version 0.43.1+)\nnetbird debug bundle --system-info --upload-bundle\n\n# Check detailed peer connection information\nnetbird status --detail --json &gt; netbird_debug_$(date +%Y%m%d_%H%M%S).json\n</code></pre> <p>Debug Bundle Flags: - <code>--anonymize (-A)</code>: Anonymizes IP addresses and non-netbird.io domains - <code>--system-info (-S)</code>: Includes network routes and interface information - <code>--upload-bundle (-U)</code>: Securely uploads bundle to NetBird support (v0.43.1+)</p> <p>Debug Information Includes: - Peer connection types (P2P vs Relayed) - ICE candidate information - WireGuard handshake timestamps - Network interface configurations - Route table information - System network configuration</p>"},{"location":"netbird/netbird_troubleshooting/#internal-network-verification","title":"Internal Network Verification","text":"<p>After establishing NetBird connection, verify internal networking:</p> <pre><code># Check route table for NetBird routes\nip route show | grep wt0\n\n# Test peer reachability within NetBird network\nping PEER_NETBIRD_IP\n\n# Verify NetBird DNS resolution (if configured)\nnslookup peer-hostname.netbird.cloud\n\n# Check internal network connectivity\nnetbird networks list\nnetbird status --detail | grep -A5 \"Routes:\"\n</code></pre>"},{"location":"netbird/netbird_troubleshooting/#troubleshooting-checklist","title":"Troubleshooting Checklist","text":"<ul> <li>[ ] NetBird service is running (<code>systemctl status netbird</code>)</li> <li>[ ] Configuration is valid (version, management URL, setup key)</li> <li>[ ] DNS resolution works for management/signal servers</li> <li>[ ] TCP connectivity to port 443 successful</li> <li>[ ] UDP connectivity to STUN servers successful (ports 3478, 19302)</li> <li>[ ] Local firewall allows required traffic</li> <li>[ ] Corporate firewall/proxy allows NetBird traffic</li> <li>[ ] WireGuard interface is up and configured</li> <li>[ ] Recent handshakes with peers (&lt; 2 minutes)</li> <li>[ ] NetBird shows \u201cConnected\u201d status</li> <li>[ ] Internal routes are established</li> <li>[ ] Peer-to-peer connectivity verified</li> <li>[ ] Debug bundle generated if issues persist</li> </ul>"},{"location":"netbird/netbird_troubleshooting/#escalation-process","title":"Escalation Process","text":"<p>If issues persist after following this guide:</p> <ol> <li>Generate debug bundle: <code>netbird debug bundle --system-info --anonymize</code></li> <li>Upload bundle (v0.43.1+): <code>netbird debug bundle --system-info --upload-bundle</code></li> <li>Collect logs: <code>journalctl -u netbird --since \"1 hour ago\" &gt; netbird_logs.txt</code></li> <li>Document symptoms: </li> <li>Connection type (P2P vs Relayed)</li> <li>ICE candidate types</li> <li>Error messages from <code>netbird status --detail</code></li> <li>Network environment (corporate firewall, NAT type)</li> <li>Contact support: </li> <li>Include debug bundle upload key or file</li> <li>Attach logs and symptom documentation</li> <li>Reference: NetBird Community Support</li> </ol>"},{"location":"tutorials/ansible_tuto/","title":"Getting Started with Ansible","text":"<p>Welcome to this beginner's guide to Ansible, a powerful automation tool that helps you manage, configure, and deploy applications to servers. In this tutorial, we'll guide you through the installation and basic usage of Ansible.</p>"},{"location":"tutorials/ansible_tuto/#what-is-ansible","title":"What is Ansible?","text":"<p>Ansible is an open-source platform used for server management, configuration, application deployment, and task automation across servers and cloud infrastructures.</p>"},{"location":"tutorials/ansible_tuto/#why-use-ansible","title":"Why Use Ansible?","text":"<p>Ansible simplifies server management and configuration. It uses tools like playbooks, ad-hoc commands, and inventory files to make infrastructure management more efficient and automated.</p>"},{"location":"tutorials/ansible_tuto/#installation","title":"Installation","text":"<p>First, ensure you have Ansible installed on your machine. Follow these instructions based on your operating system:</p>"},{"location":"tutorials/ansible_tuto/#linux","title":"Linux","text":"<pre><code>sudo apt install ansible\n</code></pre>"},{"location":"tutorials/ansible_tuto/#macos","title":"MacOS","text":"<p>First, install Homebrew (a package manager) if you haven't already:</p> <pre><code>/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\n</code></pre> <p>Then install Ansible:</p> <pre><code>brew install ansible\n</code></pre>"},{"location":"tutorials/ansible_tuto/#managing-your-first-servers","title":"Managing Your First Servers","text":""},{"location":"tutorials/ansible_tuto/#ssh-setup","title":"SSH Setup","text":"<ol> <li>Create SSH keys for authentication:</li> </ol> <pre><code>ssh-keygen -t ed25519 -f ~/.ssh/personal_key -C \"your_email@domain.com\"\n</code></pre> <p>This command creates a key that will be used for automatic authentication when logging into your servers.</p> <ol> <li>Create a new SSH key specifically for Ansible automation tasks:</li> </ol> <pre><code>ssh-keygen -t ed25519 -f ~/.ssh/ansible_key -C \"ansible@$(hostname)\"\n</code></pre> <ol> <li>Copy the SSH keys to your servers:</li> </ol> <pre><code>ssh-copy-id -i ~/.ssh/ansible_key.pub lc@188.0.0.1\n</code></pre> <pre><code>ssh-copy-id -i ~/.ssh/personal.pub  lc@188.0.0.1\n</code></pre> <p>These commands copy your authentication and Ansible SSH keys to the server, simplifying configuration and management.</p>"},{"location":"tutorials/ansible_tuto/#using-playbooks","title":"Using Playbooks","text":"<p>After setting up your SSH keys, you can use Ansible playbooks to execute tasks on your servers. A playbook is a YAML file that contains a list of tasks to be executed on the managed servers.</p> <p>Here is an example of a playbook that installs and starts the Apache web server:</p> <pre><code>- name: Install and start Apache web server\n  hosts: webservers\n  become: true # Use sudo\n  tasks:\n    - name: Install Apache\n      apt:\n        name: apache2\n        state: present\n      when: ansible_os_family == \"Debian\"\n\n    - name: Install Apache on RHEL/CentOS\n      yum:\n        name: httpd\n        state: present\n      when: ansible_os_family == \"RedHat\"\n\n    - name: Ensure Apache is started and enabled\n      service:\n        name: \"{{ 'apache2' if ansible_os_family == 'Debian' else 'httpd' }}\"\n        state: started\n        enabled: true\n</code></pre> <p>In this playbook, the <code>hosts</code> field specifies the group of servers (from the inventory file) on which the tasks will be executed. The <code>become</code> field allows the specified user to execute tasks with elevated privileges. The <code>tasks</code> field lists the actions to be performed on the servers, such as installing packages and starting services.</p>"},{"location":"tutorials/ansible_tuto/#inventory-file","title":"Inventory File","text":"<p>The inventory file defines the servers managed by Ansible and organizes them into groups based on their roles or purposes. Here is an example:</p> <pre><code>[web]\n192.168.1.10 ansible_user=ubuntu\n192.168.1.11 ansible_user=ubuntu\n\n[db]\n192.168.1.12 ansible_user=root\n</code></pre> <p>In this example, the servers are grouped into <code>web</code> and <code>db</code> groups, indicating their respective roles as web servers and database servers.</p>"},{"location":"tutorials/ansible_tuto/#using-ad-hoc-commands","title":"Using Ad-hoc Commands","text":"<p>Ad-hoc commands are used to run single, simple tasks on your servers without the need to write a playbook. Here are some examples:</p> <ul> <li>Ping All Servers</li> </ul> <pre><code>ansible all -i hosts.ini -m ping\n</code></pre> <ul> <li>Reboot Web Servers</li> </ul> <pre><code>ansible web -i hosts.ini -a \"reboot\" -b\n</code></pre> <ul> <li>Install VLC on Web Servers</li> </ul> <pre><code>ansible web -i hosts.ini -b -m apt -a \"name=vlc state=present\"\n</code></pre> <p>Ad-hoc commands are useful for performing quick tasks, such as installing a package or rebooting a server.</p>"},{"location":"tutorials/ansible_tuto/#conclusion","title":"Conclusion","text":"<p>In this tutorial, we covered the basics of Ansible, including its installation, configuration, and usage of playbooks and ad-hoc commands. Ansible is a powerful tool that can greatly simplify the management and automation of tasks across your servers and infrastructure.</p>"},{"location":"tutorials/boot_docs/","title":"HOW TO INSTALL A UBUNTU SERVER 24.04 STEP-BY STEP","text":""},{"location":"tutorials/boot_docs/#overview","title":"Overview","text":"<p>What is Ubuntu</p> <p>Ubuntu is one of the most widely used and popular Linux distributions, that comes in multiple editions including Ubuntu Desktop, Ubuntu Server, and Ubuntu Core to mention a few.</p> <p>Why Ubuntu servers</p> <p>Ubuntu Server is built for server environments, which is a lightweight and minimal version that is stripped off of any GUI applications and elements to enhance the speed and performance of running production-grade applications. It can serve as a web server, file server, development server, and DNS server to mention a few use cases.</p>"},{"location":"tutorials/boot_docs/#ubuntu-server-vs-other-server-osdistros","title":"Ubuntu Server vs Other Server OS/Distros","text":"Aspect Ubuntu Server Debian CentOS / RHEL Windows Server Ability Full-featured Linux server OS; supports wide range of services and apps Highly capable, but less user-friendly out of the box Enterprise-focused capabilities; stable environments Supports many enterprise tools, Active Directory, .NET, etc. Capacity Easily supports heavy workloads with proper configuration Handles large workloads, but tuning may require more expertise Designed for enterprise-scale operations Capable of high capacity but with more resource overhead Performance Lightweight by default; minimal system load; high efficiency Very lightweight; excellent performance, especially on older hardware Moderate; built for stability over raw performance Heavier footprint; performance affected by GUI and background services Safety Strong package integrity checks; frequent security patches Conservative approach ensures safety, but slower update cycle SELinux integration improves isolation and safety Closed-source; safety reliant on Microsoft\u2019s update cycle Security AppArmor, UFW firewall, automatic security updates available Manual setup required for many security features SELinux is powerful but complex; good enterprise controls Proprietary model limits transparency; patching is slower Scalability Well-suited for cloud environments, containers, and large-scale deployments Scalable, but lacks vendor-optimized tools for automation Highly scalable; used in many large enterprise networks Scales in enterprise settings but with higher resource and license costs <p>Prerequisites</p> <ul> <li>Minimal 4 GB of RAM</li> <li>2 GHz dual-core processor</li> <li>25 GB disk space</li> <li>Internet Connectivity (Optional)</li> <li>Installation Media (bootable USB or DVD).</li> </ul> <p>What you'll learn</p> <p>How you will make a Ubuntu server bootable key and also how to install Ubuntu server 24.04 on a computer.</p>"},{"location":"tutorials/boot_docs/#get-started","title":"Get started","text":"<ol> <li>Download the Ubuntu Server ISO Image</li> </ol> <p>The first step is to download the Ubuntu server 24.04 ISO image. So, head over to the official Ubuntu download page (https://ubuntu.com/download/server) and download the ISO file. With the ISO file at hand, prepare the installation media by burning the ISO file into USB. You can use a software utility such as Rufus if you are running Windows or UNetbootin or balenaEtcher for Linux, macOS, and Windows. In this tutor we'll use balenaEtcher, get to the balenaEtcher page (https://etcher-docs.balena.io/) to download balenaEtcher, here are the steps to burn the ISO image:</p> <p>i. launch balenaEtcher</p> <pre><code>click on the \"balenaEtcher\" icon to start balenaEtcher.\n</code></pre> <p></p> <p>ii. locating the image file</p> <pre><code>click on \"flash from file\" to select your image file.\n</code></pre> <p></p> <p>iii. choosing the storage device</p> <pre><code>click on \"select target\" to select your storage device.\n</code></pre> <p></p> <p>iv. flash the USB drive</p> <pre><code>click on \"flash\" to make the bootable flash.\n</code></pre> <p></p> <ol> <li>Start Ubuntu Server Installation</li> </ol> <p>With the USB boot medium in place, plug it into the system you want to install the Ubuntu server OS and reboot. Be sure to configure your bootable medium to take the highest boot priority in the BIOS and continue booting.</p> <p>Upon booting, you will see the GRUB menu with two options: \u201cTry or Install Ubuntu Server\u201d and \u201cTest memory\u201c. The first option comes pre-selected. This is what we want. So just hit ENTER to proceed.</p> <p></p> <p>You will see some boot messages on the screen for a few seconds.</p> <p></p> <ol> <li>Choose your language</li> </ol> <p>Once the system has finished booting, select your preferred installation language. By default, this is set to English. This looks good for our case, so hit ENTER to proceed to the next step </p> <ol> <li>Select Keyboard Layout</li> </ol> <p>Next, select your preferred layout. The default selection for the layout and variant is English (US). Feel free to select your preferred option, select <code>Done</code> with your arrow key, and hit ENTER to proceed to the next step. </p> <ol> <li>Choose the Type of Installation</li> </ol> <p>The next step will require you to select your preferred installation type. By default, the \u201cUbuntu Server\u201d option is selected. In addition to that, you can also choose the \u201cUbuntu Server (\u201cminimized\u201d) option which is a version customized to have a small footprint in environments that do not require login by users.</p> <p>In this guide, we will go with the \u201cUbuntu Server\u201d option. So we will hit ENTER.</p> <p></p> <ol> <li>configure network</li> </ol> <p>In this step, you need to configure at least one active interface for network and internet connection. Active connections will be displayed with corresponding IPv4 addresses since DHCP is selected by default.</p> <p></p> <p>In our setup, \u201cenp0s3\u201d is the only active network interface. Instead of DHCP, we will configure a static IP address since the instance will act as a server.</p> <p>So, ensure your active interface is selected, then hit the arrow-right key on the keyboard, and on the menu that appears, select <code>Edit IPv4</code> using the arrow-down key.</p> <p></p> <p>On the pop-up CLI that appears, select the <code>Manual</code> option and hit ENTER.</p> <p></p> <p>Be sure to fill in the IP details, i.e. Subnet, IP address, gateway, Nameservers, and Search domains, if any. Then select <code>Save</code> and hit ENTER.</p> <p></p> <p>Next, select <code>Done</code> and hit ENTER.</p> <p></p> <ol> <li>Configure Proxy</li> </ol> <p>If you intend to connect to a Proxy server, here\u2019s the chance to provide your Proxy server address. If you are not running a proxy server, leave it blank and hit <code>Done</code>.</p> <p></p> <p>The installer will perform a mirror test by updating the package index. The default mirror address is http://archive.ubuntu.com/ubuntu/ which is just fine. You can also provide an alternative mirror instead of the default one.</p> <p>Once the mirror test is complete, select <code>Done</code> and hit ENTER.</p> <p></p> <p>In this step, you will be required to configure disk partitions. By default, guided storage is selected. This auto-partitions your hard drive using the most recommended settings based on the size of your drive.</p> <p>The other option \u2013 \u201cCustom storage layout\u201d \u2013 lets you manually specify the partitions including the partition type and size.</p> <p>For simplicity, we will go with the first option \u2013 \u201cGuided storage layout\u201c. With this option selected, installer will intelligently partition the disk for you and allocate space for swap, /boot, and / ( root ) partitions.</p> <p>Select <code>Done</code> and hit ENTER.</p> <p></p> <p>The partition table will be displayed next. If all looks good, select <code>Done</code> and hit ENTER. Otherwise, if you need to make some changes, select <code>Reset</code> and hit ENTER to head back and make the needed adjustment.</p> <p></p> <p>On the pop-up window that appears, select <code>Continue</code> and hit ENTER to write the changes to disk.</p> <p></p> <ol> <li>Create a User Account</li> </ol> <p>Next, you will be required to create a user account. So, provide the required details including your name, the server\u2019s name, username, and password, and hit ENTER to move to the next step.</p> <p></p> <ol> <li>Select whether to enable Ubuntu Pro</li> </ol> <p>Ubuntu Pro is an additional service on top of Ubuntu that provides extended support and maintenance including compliance for your OS. It provides 10 years of paid support and you can use up to 5 devices free for personal use. This, however, requires a Ubuntu One account.</p> <p>For now, we will skip this \u2013 You can enable it later. So hit <code>Continue</code>.</p> <p></p> <ol> <li>Select Whether to install the OpenSSH server &amp; additional software</li> </ol> <p>Next, select whether you want to install the OpenSSH server which will allow remote login to the server. In our case, we will select to install it. Once selected, select <code>Done</code> and hit ENTER.</p> <p></p> <p>Next, you will be required to select whether to install some featured applications in the form of snaps. So go through the list and enable your preferred snap. Alternatively, you can skip and install them later.</p> <p>For now, we will not install snaps. So select <code>Done</code> and hit ENTER.</p> <p></p> <ol> <li>Finish the Installation and Reboot</li> </ol> <p>From here, the installer will copy all the files from the bootable medium install them on your hard drive, and configure all the required settings.</p> <p></p> <p>Finally, select <code>Done</code> and hit ENTER to reboot.</p> <p></p> <p>Once the system has rebooted, provide your user account\u2019s password and hit ENTER to log in.</p> <p></p> <p>From now you can enjoy your Ubuntu server 24.04 LTS installation. If you are new to Ubuntu server, we'd recommend reading the server guide</p>"},{"location":"tutorials/boot_docs/#security-measures","title":"Security measures","text":"<p>When installing an Ubuntu Server, several security considerations are important to ensure the system's safety. some steps are as follows:</p> <ol> <li>Ensuring that the system is updated regularly to apply the latest security patches and bug fixes.</li> <li>Using a firewall, such as Uncomplicated Firewall(ufw), to only allow necessary ports is also essential.</li> <li>securing shared memory by adding specific configurations to /etc/fstab can improve security.</li> <li>securing SSH service.</li> <li>Lastly, it is recommended to install security tools like Fail2ban to monitor and block malicious login attempts and to use security-enhancing features like AppArmor to restrict application permissions.</li> </ol>"},{"location":"tutorials/boot_docs/#troubleshooting-partition-issues","title":"Troubleshooting partition issues","text":"<p>If by the end while terminating the installation you get any error, then it means that you have a partition issue, and this is how you can resolve it:</p> <p>1- Download the Ubuntu 24.04 ISO image from the official Ubuntu website.</p> <p>2- Write the ISO image to a USB stick using a tool like balenaEtcher or the Startup Disk Creator.</p> <p>3- Boot your machine from the USB stick. You may need to enter the boot menu (commonly accessed with F12, Escape, F2, or F10) to select the USB device as the boot device.</p> <p>4- Once the USB boots, select the \"Try Ubuntu\" option from the GRUB bootloader.</p> <p>5- Choose your language and follow the installation wizard's instructions. If you encounter issues with graphics, select \"safe graphics\" mode.</p> <p>After your desktop environment has been setup, press \"Ctrl + alt + t\" to open a new terminal session.</p> <p>1- Identify the target disk</p> <p>Run:</p> <pre><code>lsblk\n</code></pre> <p>Example output:</p> <pre><code>NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\nsda      8:0    0  500G  0 disk\n\u251c\u2500sda1   8:1    0  100G  0 part /\n\u251c\u2500sda2   8:2    0  400G  0 part /home\nsdb      8:16   0  250G  0 disk\n</code></pre> <p>Suppose <code>sdb</code> is the disk you want to wipe and repartition.</p>"},{"location":"tutorials/boot_docs/#using-fdisk-for-mbrgpt","title":"Using <code>fdisk</code> (for MBR/GPT)","text":""},{"location":"tutorials/boot_docs/#2-launch-fdisk","title":"2. Launch <code>fdisk</code>","text":"<pre><code>sudo fdisk /dev/sdb\n</code></pre>"},{"location":"tutorials/boot_docs/#3-inside-fdisk-interactive-mode","title":"3. Inside <code>fdisk</code> (interactive mode)","text":"<p>Press keys as prompted:</p> <ol> <li>Type <code>g</code> to create a new GPT partition table (or <code>o</code> for MBR).</li> <li>Type <code>d</code> to delete partitions (repeat until they're all gone).</li> <li>Type <code>n</code> to create a new partition.</li> <li>Type <code>w</code> to write changes and exit.</li> </ol> <p>Sample flow:</p> <pre><code>Command (m for help): g\nCreated a new GPT disklabel.\n\nCommand (m for help): d\n(No partition is currently defined, skip if none)\n\nCommand (m for help): n\nPartition number (1-128, default 1): &lt;Enter&gt;\nFirst sector (2048-...), default 2048: &lt;Enter&gt;\nLast sector, +sectors or +size{K,M,G,T,P}: &lt;Enter&gt;\n\nCommand (m for help): w\n</code></pre>"},{"location":"tutorials/boot_docs/#4-format-the-new-partition","title":"4. Format the new partition","text":"<p>Assuming it created <code>/dev/sdb1</code>, format it:</p> <pre><code>sudo mkfs.ext4 /dev/sdb1\n</code></pre> <p>(Use <code>mkfs.xfs</code> or <code>mkfs.ntfs</code> if you prefer other filesystems.)</p>"},{"location":"tutorials/boot_docs/#5-mount-it-optional","title":"5. Mount it (optional)","text":"<pre><code>sudo mkdir /mnt/newdisk\nsudo mount /dev/sdb1 /mnt/newdisk\n</code></pre> <p>To mount it automatically at boot, you'd edit <code>/etc/fstab</code>.</p>"},{"location":"tutorials/minimal_kvm_setup/","title":"Install QEMU, KVM, and Libvirt on Ubuntu Server using Ansible","text":"<p>This guide documents how to use Ansible to install and configure QEMU, KVM, and Libvirt on Ubuntu servers without a graphical interface.</p>"},{"location":"tutorials/minimal_kvm_setup/#what-it-does","title":"What It Does","text":"<ul> <li>Installs virtualization tools: <code>qemu-kvm</code>, <code>libvirt</code>, <code>bridge-utils</code>, <code>virtinst</code></li> <li>Starts and enables the <code>libvirtd</code> service</li> <li>Adds the current user to <code>kvm</code> and <code>libvirt</code> groups</li> </ul>"},{"location":"tutorials/minimal_kvm_setup/#files","title":"Files","text":"<ul> <li><code>scripts/minimal_kvm_setup.yml</code>: Ansible playbook to automate installation</li> <li><code>inventory.ini</code>: Inventory file listing target Ubuntu hosts</li> <li><code>docs/tutorials/minimal_kvm_setup.md</code>: This documentation</li> </ul>"},{"location":"tutorials/minimal_kvm_setup/#requirements","title":"Requirements","text":"<ul> <li>Ubuntu 20.04+ servers with SSH access</li> <li>A control node with Ansible installed</li> <li>SSH key-based authentication to target servers</li> </ul>"},{"location":"tutorials/netbird_wazuh_integration/","title":"Integrating NetBird With Wazuh","text":"<p>Wazuh is a SIEM and event logger system that is used to monitor systems for networks vulnerabilities, file integrity and also monitor logs for suspicious events on a system.</p> <p>NetBird is a zero trust VPN that is built on top of WireGuard which is used to create secure and encrypted tunnel for peer-to-peer connection and communication over a network.</p> <ul> <li>NetBird is an easy to use interface that help you to use the WireGuard   protocol directly without all the complexities of configuring them.</li> <li>WireGuard protocol is also lightweight and more secured as compared to other   VPN technologies like OpenVPN.</li> </ul> <p>NetBird has two monitoring functions that helps it to keep track of all what is going on in the network.</p>"},{"location":"tutorials/netbird_wazuh_integration/#1-audit-event","title":"1. Audit Event","text":"<p>This is used to monitor the activities and events that are occurring in the NetBird network, like a new user being added, a new instance or peer joining the network, new setup-key created, updated policy or policy created etc.</p>"},{"location":"tutorials/netbird_wazuh_integration/#2-traffic-event","title":"2. Traffic Event","text":"<p>This is used to monitor how traffic flows within the netbird network and it also helps us to track who is making what request to who. It can help us to see who is making brute force request and any attempt to masquerade. I track all failed attempt to connect to different peers in the network.</p> <p>This is the log that is collected from netbird and monitored by wazuh </p>"},{"location":"tutorials/netbird_wazuh_integration/#this-is-a-full-list-of-events-tracked-by-netbird","title":"This is a full list of events tracked by NetBird","text":"<ul> <li>Peer Management:</li> <li>Peer added by user</li> <li>Peer added with setup key</li> <li>Peer removed by user</li> <li>Peer renamed</li> <li>Peer SSH server enabled</li> <li>Peer SSH server disabled</li> <li>Peer login expiration enabled</li> <li> <p>Peer login expiration disabled</p> </li> <li> <p>User Management:</p> </li> <li>User joined</li> <li>User invited</li> <li>User role updated</li> <li>User blocked</li> <li>User unblocked</li> <li> <p>User deleted</p> </li> <li> <p>Group Management:</p> </li> <li>Group created</li> <li>Group updated</li> <li>Group deleted</li> <li>Group added to peer</li> <li>Group removed from peer</li> <li>Group added to user</li> <li>Group removed from user</li> <li>Group added to setup key</li> <li>Group removed from setup key</li> <li>Group added to disabled management DNS setting</li> <li>Group removed from disabled management DNS setting</li> <li>Policy Management:</li> <li>Policy added</li> <li>Policy updated</li> <li>Policy removed</li> <li>Rule Management:</li> <li>Rule added</li> <li>Rule updated</li> <li>Rule removed</li> <li>Setup Key Management:</li> <li>Setup key created</li> <li>Setup key updated</li> <li>Setup key revoked</li> <li>Setup key overused</li> <li>Route Management:</li> <li>Route created</li> <li>Route removed</li> <li>Route updated</li> <li>Account Management:</li> <li>Account created</li> <li>Account peer login expiration duration updated</li> <li>Account peer login expiration enabled</li> <li>Account peer login expiration disabled</li> <li>Account peer approval enabled</li> <li>Account peer approval disabled</li> <li>nameserver Group Management:</li> <li>nameserver group created</li> <li>nameserver group deleted</li> <li>nameserver group updated</li> <li>Token Management:</li> <li>Personal access token created</li> <li>Personal access token deleted</li> <li>Service User Management:</li> <li>Service user created</li> <li>Service user deleted</li> <li>Integration Management:</li> <li>Integration created</li> <li>Integration updated</li> <li>Integration deleted</li> <li>Other Events:</li> <li>Transferred owner role</li> <li>Posture check created</li> <li>Posture check updated</li> <li>Posture check deleted</li> <li>User logged in peer</li> <li>Peer login expired</li> <li>Dashboard login</li> </ul> <p>This reference will take you to the integration of NetBird with SIEM systems NetBird + SIEM</p> <ul> <li>I installed Wazuh and wanted to make the NetBird cloud forward the logs to my   Python server so that it can write it in a file that Wazuh can monitor.</li> <li>This is the script to monitor.</li> </ul> <pre><code># this is the command to install wazuh\ncurl -sO https://packages.wazuh.com/4.13/wazuh-install.sh &amp;&amp; sudo bash ./wazuh-install.sh -a\n</code></pre> <p>After this command you will see the login credentials and the URL to your NetBird dashboard or just your localhost or machine IP on port 143.</p> <ul> <li> <p>But I could not because I needed to give my VM a public IP or domain name before   I could do that.</p> </li> <li> <p>Also, to self-host NetBird, you need to have a public domain name or public IP. The self-hosted version of NetBird does not allow for event streaming to monitor the traffic and activities of NetBird using a third-party SIEM.</p> </li> </ul> <p>So I thought of using a free domain name provider that would incur no cost.</p> <ul> <li> <p>I found that most of these domain name providers actually have a free tier   that is limited and will only work for testing purposes.</p> </li> <li> <p>But I found this:</p> </li> </ul> <p><code>Instead of a true public IP, you can use a tunneling service to expose a local   web server running inside your Multipass VM to the public internet. This approach   is free and widely used for development and testing.</code></p> <ul> <li>The best one that suits this purpose is using a Cloudflare tunneling   service that will actually give us a fake public IP that we can somehow use</li> </ul> <p>I use Cloudflare to create a public domain name that my NetBird cloud could use to forward messages to my Python server listening on port 8080.</p>"},{"location":"tutorials/netbird_wazuh_integration/#this-is-the-setup-of-using-cloudflare","title":"This is the setup of using Cloudflare","text":"<ul> <li>Start by installing Cloudflare</li> </ul> <pre><code> curl -L https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb -o cloudflared.deb\n sudo dpkg -i cloudflared.deb\n</code></pre> <ul> <li>Then log in and you will be redirected or else you will see a redirection URL to log in or create an account if you don't have one.</li> </ul> <pre><code> #this is the command to login\n cloudflared tunnel login\n</code></pre> <ul> <li>Then after that you need to create a temporary trycloudflare-endpoint or    domain name with the port you want to listen to and only that port will be    exposed when it is up.</li> </ul> <pre><code>cloudflared tunnel --url http://localhost:8080\n</code></pre> <ul> <li>Next you will see it at the top of the logs that will be displayed.</li> </ul> <pre><code>2025-09-24T08:18:05Z INF Requesting new quick Tunnel on trycloudflare.com...\n2025-09-24T08:18:12Z INF +--------------------------------------------------------------------------------------------+\n2025-09-24T08:18:12Z INF |  Your quick Tunnel has been created! Visit it at (it may take some time to be reachable):  |\n2025-09-24T08:18:12Z INF |  https://sporting-goodtolook-thing-builder.trycloudflare.com                                 |\n2025-09-24T08:18:12Z INF +------------------------------------------------------+\n</code></pre> <ul> <li>I wrote a Python script to receive incoming logs on that port 8080 and the   servers was up when I ran it. So ensure that the server is up before you run   <code>cloudflared tunnel --url</code> command.   </li> <li>I took this URL <code>https://sporting-goodtolook-thing-builder.trycloudflare.com</code>   and added in the URL section in the Generic HTTP function on NetBird so my   logs can be forwarded.</li> <li>Allow all the servers to be running until you are done</li> </ul>"},{"location":"tutorials/netbird_wazuh_integration/#integrating-with-wazuh","title":"Integrating with Wazuh","text":"<p>Now Wazuh that you deployed just needs to monitor the file where you are forwarding the logs to.</p> <ul> <li>I edited a few files and added some extra content to include my logs to be   monitored.</li> </ul> <pre><code>&lt;!-- \nsudo nano /var/ossec/etc/ossec.conf\nadd the following content in the &lt;ossec_config&gt; section.\n --&gt;\n&lt;localfile&gt;\n  &lt;log_format&gt;json&lt;/log_format&gt;\n  &lt;location&gt;/var/log/netbird/activity.json&lt;/location&gt;\n&lt;/localfile&gt;\n\n&lt;!-- this one is for other files that needs to be monitored --&gt;\n&lt;localfile&gt;\n  &lt;log_format&gt;syslog&lt;/log_format&gt;\n  &lt;location&gt;/var/log/netbird/client.log&lt;/location&gt;\n&lt;/localfile&gt;\n&lt;localfile&gt;\n  &lt;log_format&gt;syslog&lt;/log_format&gt;\n  &lt;location&gt;/var/log/netbird/netbird.err&lt;/location&gt;\n&lt;/localfile&gt;\n&lt;localfile&gt;\n  &lt;log_format&gt;syslog&lt;/log_format&gt;\n  &lt;location&gt;/var/log/netbird/netbird.out&lt;/location&gt;\n&lt;/localfile&gt;\n</code></pre> <ul> <li>Now I check the permission of those files and make sure that Wazuh has the   right to read them</li> </ul> <pre><code>ls -l /var/log/netbird/\nsudo usermod -aG root wazuh\n</code></pre> <ul> <li>I used default decoders and configured rules  so that they can be able to throw alert messages for some events that will happen like changing or adding new policy, setup key deleted or created. When these rules are met, an alert is being fired to my email.</li> </ul> <pre><code>&lt;group name=\"netbird,\"&gt;\n  &lt;rule id=\"100000\" level=\"5\"&gt;\n    &lt;decoded_as&gt;json&lt;/decoded_as&gt;\n    &lt;field name=\"Message\"&gt;peer ssh server disabled&lt;/field&gt;\n    &lt;description&gt;NetBird SSH access for a peer has been disabled.&lt;/description&gt;\n  &lt;/rule&gt;\n\n  &lt;rule id=\"100002\" level=\"7\" overwrite=\"yes\"&gt;\n    &lt;field name=\"Message\" type=\"pcre2\"&gt;^setup key deleted&lt;/field&gt;\n    &lt;description&gt;NetBird setup key deleted by user.&lt;/description&gt;\n  &lt;/rule&gt;\n&lt;/group&gt;\n</code></pre> <ul> <li>After which I restarted the Wazuh manager and that was it</li> </ul> <pre><code>sudo systemctl restart wazuh-manager\n</code></pre> <p> I then went to the Wazuh dashboard under the discover section and I found the logs from Wazuh and my local machine where the server is running.</p> <p>Wazuh Security Events only display messages on the dashboard that are triggered by rules.</p> <p></p> <p>Without a rule, the NetBird logs exist in the raw archives but will not be considered \"security events.\" and so will be discarded after some time to save space for events that need to be displayed on the Wazuh dashboard since this Wazuh is for monitoring critical events.</p> <p>This thing is becoming serious I have done some little modifications in the <code>/var/ossec/etc/rules/local_rules.xml</code> file and it worked. Now I have configured my email according to the documentation of Wazuh to act as a relay host so that it can be used to forward emails to users that I specify in the <code>&lt;email_to&gt;</code> tag under the <code>&lt;global&gt;</code> section of the <code>&lt;ossec_config&gt;</code>.  Alerting on Wazuh</p> <p>This is the config file used to configure relayhost for wazuh to use to forward email.</p> <pre><code>##filename  /etc/postfix/main.cf\n\n# See /usr/share/postfix/main.cf.dist for a commented, more complete version\n\n\n# Debian specific:  Specifying a file name will cause the first\n# line of that file to be used as the name.  The Debian default\n# is /etc/mailname.\n#myorigin = /etc/mailname\n\nsmtpd_banner = $myhostname ESMTP $mail_name (Ubuntu)\nbiff = no\n\n# appending .domain is the MUA's job.\nappend_dot_mydomain = no\n\n# Uncomment the next line to generate \"delayed mail\" warnings\n#delay_warning_time = 4h\n\nreadme_directory = no\n\n# See http://www.postfix.org/COMPATIBILITY_README.html -- default to 3.6 on\n# fresh installs.\ncompatibility_level = 3.6\n\n\n\n# TLS parameters\nsmtpd_tls_cert_file=/etc/ssl/certs/ssl-cert-snakeoil.pem\nsmtpd_tls_key_file=/etc/ssl/private/ssl-cert-snakeoil.key\nsmtpd_tls_security_level=may\n\nsmtp_tls_CApath=/etc/ssl/certs\nsmtp_tls_security_level=may\nsmtp_tls_session_cache_database = btree:${data_directory}/smtp_scache\n\n\nsmtpd_relay_restrictions = permit_mynetworks permit_sasl_authenticated defer_unauth_destination\nmyhostname = network-vm.tail431420.ts.net\nalias_maps = hash:/etc/aliases\nalias_database = hash:/etc/aliases\nmyorigin = /etc/mailname\nmydestination = $myhostname, netbird-noreply@wazuh.com, network-vm, localhost.localdomain, localhost\n#relayhost =\nmynetworks = 127.0.0.0/8 [::ffff:127.0.0.0]/104 [::1]/128\nmailbox_size_limit = 0\nrecipient_delimiter = +\ninet_interfaces = all\ninet_protocols = all\n\n# Relay settings\nrelayhost = [smtp.gmail.com]:587\nsmtp_sasl_auth_enable = yes\nsmtp_sasl_password_maps = hash:/etc/postfix/sasl_passwd\nsmtp_sasl_security_options = noanonymous\nsmtp_use_tls = yes\n</code></pre> <p>Also you will need to create an password with google if you want to use gmail as your relay server.</p>"},{"location":"tutorials/ntp_setup_tuto/","title":"NTP Setup Tutorial","text":"<p>As discussed in the NTP documentation, NTP (Network Time Protocol) is used to synchronize time across all servers in an infrastructure. In this tutorial, we'll learn how to install and configure NTP using an Ansible playbook.</p> <p>Ansible automates tasks through playbooks, which define the desired state of systems. We'll write a playbook to install NTP on all servers.</p>"},{"location":"tutorials/ntp_setup_tuto/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding, make sure you understand how playbooks work by reviewing this guide:</p> <ul> <li>Ansible Playbook Basics</li> </ul>"},{"location":"tutorials/ntp_setup_tuto/#playbook-initialization","title":"Playbook Initialization","text":"<p>To begin writing a playbook, you generally follow a common structure made up of the following main keys:</p> <pre><code>name    # The name of the playbook\nhosts   # Target servers where tasks will run\nbecome  # Whether to use sudo privileges\ntasks   # List of tasks to execute\n</code></pre>"},{"location":"tutorials/ntp_setup_tuto/#understanding-the-structure","title":"Understanding the Structure","text":"<ol> <li> <p>Name: For our NTP setup, we give the playbook a descriptive name like \"Installing NTP via Ansible\"</p> </li> <li> <p>Hosts: Specifies the group of servers where the tasks should run. We'll set it to <code>all</code>, meaning we want the NTP service installed on all target servers</p> </li> <li> <p>Become: Allows tasks to be executed with sudo privileges. Since installing NTP requires elevated permissions, we'll set this to <code>yes</code></p> </li> <li> <p>Tasks: Defines the actual steps Ansible should perform. Each task can use modules like the package manager. We'll use <code>apt</code> to install the NTP package</p> </li> </ol> <p>Additionally, we use <code>update_cache: yes</code> to ensure that the package list is up-to-date before installation, so the latest version of NTP is installed.</p> <p>Here's our complete playbook:</p> <pre><code>- name: Installing NTP service\n  hosts: all\n  become: yes\n  tasks:\n    - name: Install NTP package\n      apt:\n        name: ntp\n        state: present\n        update_cache: yes\n</code></pre>"},{"location":"tutorials/ntp_setup_tuto/#running-the-playbook","title":"Running the Playbook","text":"<p>To execute the playbook, run this command:</p> <pre><code>ansible-playbook -i inventory.ini playbook.yml\n</code></pre> <p>The <code>inventory.ini</code> file is where all your server identities are placed. Follow this to learn more about <code>inventory.ini</code>:</p> <ul> <li>Ansible Inventory Documentation</li> </ul>"},{"location":"tutorials/ntp_setup_tuto/#conclusion","title":"Conclusion","text":"<p>That's it! You've now learned how to install NTP using an Ansible playbook to synchronize time across your servers. This is an essential step in managing distributed systems to ensure consistent timekeeping and prevent potential issues.</p>"},{"location":"tutorials/setupvswitch/","title":"How to Set Up a Virtual Switch with Multipass","text":"<p>In this tutorial, we will configure a virtual switch (vswitch) for Multipass instances and make them accessible over the network.</p>"},{"location":"tutorials/setupvswitch/#what-is-a-switchbridge-and-why-do-we-use-it","title":"What is a Switch/Bridge and Why Do We Use It?","text":"<p>A switch is a networking device that helps us connect different computers together using ethernet cables. The switch has a MAC table that it uses to determine which computer on the network it is supposed to send data packets to. It is also one of the major component devices of layer 2 of the OSI model.</p> <p>A bridge is a device that connects two or more local area networks (LANs) that use the same protocol. Bridges act the same way as switches (Virtual Switches in our case).</p> <p>We are using a bridge here because our VMs are isolated from our host and we need to connect them so that they can talk with each other. A bridge allows the VMs to talk to each other as if they were on the same network.</p>"},{"location":"tutorials/setupvswitch/#main-functions-of-a-bridge","title":"Main Functions of a Bridge","text":"<ul> <li>Combines multiple VMs/Containers into a single logical network</li> <li>Maintains MAC address table to intelligently forward frames</li> <li>Allows devices on the same bridge to communicate directly (except when separated by VLANs)</li> </ul>"},{"location":"tutorials/setupvswitch/#network-topology-overview","title":"Network Topology Overview","text":"<pre><code>graph TD\n    subgraph Host\n        OVS[OVS Bridge: virt-bridge]\n        OVS_VLAN0[OVS VLAN0]\n        OVS_VLAN1[OVS VLAN1]\n    end\n\n    VM1 --&gt;|ens3| OVS_VLAN0\n    VM2 --&gt;|ens3| OVS_VLAN0\n    VM3 --&gt;|ens3| OVS_VLAN1\n    VM4 --&gt;|ens3| OVS_VLAN1\n\n    OVS_VLAN0 --&gt; OVS\n    OVS_VLAN1 --&gt; OVS</code></pre>"},{"location":"tutorials/setupvswitch/#prerequisites","title":"Prerequisites","text":"<p>To follow along in this course, you will need:</p> <ul> <li>Ubuntu 22.04 LTS or Ubuntu 24.04 LTS</li> <li>Multipass installed</li> <li>Root permission or sudo if the user is in the sudoers group</li> <li><code>ovs-vsctl</code> installed for creating bridges and adding ports</li> </ul> <p>The Open vSwitch (OVS) supports virtual LAN technology that helps us split our virtual network into smaller logical partitions for security enforcement:</p> <pre><code>sudo apt install -y openvswitch-switch\n</code></pre>"},{"location":"tutorials/setupvswitch/#creating-a-virtual-network","title":"Creating a Virtual Network","text":"<p>After putting in place all the requirements, let's dive in!</p>"},{"location":"tutorials/setupvswitch/#setting-up-the-virtual-switch","title":"Setting Up the Virtual Switch","text":"<p>First, we will create a Virtual Switch with VLAN support:</p> <pre><code># Create Open Virtual Switch (OVS)\nsudo ovs-vsctl add-br virt-bridge\nip link set virt-bridge up # to make it known to your system\n\n# List available bridges\nsudo ovs-vsctl list-br\n\n# Configure VLANs on the OVS\nsudo ovs-vsctl set port virt-bridge vlan_mode=native-untagged\nsudo ovs-vsctl set port virt-bridge trunks=0,1 # to allow VLAN0 and VLAN1\n</code></pre>"},{"location":"tutorials/setupvswitch/#creating-the-vms","title":"Creating the VMs","text":"<p>Now let's create 4 VMs labeled test-vm1 through test-vm4:</p> <pre><code># Creating VMs with a simple script\nfor i in {1..4}; do\n    multipass launch --name test-vm$i --network name=virt-bridge --network name=default 24.04\ndone\n</code></pre> <p>This creates 4 VMs running Ubuntu 24.04.</p>"},{"location":"tutorials/setupvswitch/#configuring-vlan-tags","title":"Configuring VLAN Tags","text":"<p>Now we'll configure the VLAN tags. VLAN uses the 802.1Q standard, adding a 12-bit tag to L2 packets that can only be decrypted by machines on the same VLAN.</p> <ol> <li>First, check available interfaces in your VMs:</li> </ol> <pre><code>multipass exec \"test-vm1\" -- ip -o link show | awk -F ': ' '!/lo/ {print $2; exit}'\n# Repeat for other VMs. Use your interface name if not ens3\n</code></pre> <ol> <li>Add machines to VLAN0:</li> </ol> <pre><code>multipass stop test-vm1 test-vm2 # stop VMs before adding ports\nsudo ovs-vsctl set port test-vm2-ens3 tag=0\nsudo ovs-vsctl set port test-vm1-ens3 tag=0\nmultipass start test-vm1 test-vm2\n</code></pre> <ol> <li>Add machines to VLAN1:</li> </ol> <pre><code>multipass stop test-vm3 test-vm4\nsudo ovs-vsctl set port test-vm3-ens3 tag=1\nsudo ovs-vsctl set port test-vm4-ens3 tag=1\nmultipass start test-vm3 test-vm4\n</code></pre> <ol> <li>Verify port settings:</li> </ol> <pre><code>sudo ovs-vsctl show | grep -A 2 \"Port\"\n</code></pre>"},{"location":"tutorials/setupvswitch/#network-interface-configuration","title":"Network Interface Configuration","text":"<p>Now we'll configure static IPs for each VM:</p> <ol> <li>For VLAN0 (test-vm1 and test-vm2):</li> </ol> <pre><code>multipass exec test-vmX -- sudo ip link set ens3 up\nsudo ip addr add 192.168.100.10X dev ens3\n</code></pre> <ol> <li>For VLAN1 (test-vm3 and test-vm4):</li> </ol> <pre><code>multipass exec test-vmX -- sudo ip link set ens3 up\nsudo ip addr add 192.168.200.10X dev ens3\n</code></pre>"},{"location":"tutorials/setupvswitch/#testing-connectivity","title":"Testing Connectivity","text":"<p>Let's verify our network configuration:</p> <pre><code># Test connectivity\nmultipass exec test-vm1 -- ping -c 5 192.168.100.102 # Should work\nmultipass exec test-vm2 -- ping -c 5 192.168.200.103 # Should not work\n</code></pre>"},{"location":"tutorials/setupvswitch/#summary","title":"Summary","text":"<p>In this tutorial, we have covered:</p> <ul> <li>Creating a network bridge</li> <li>Adding VMs to a network/bridge (always stop instances before attaching)</li> <li>Creating and configuring VLANs</li> <li>Setting static IPv4 addresses for VM instances</li> </ul>"}]}